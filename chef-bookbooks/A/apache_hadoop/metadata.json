{
  "name": "apache_hadoop",
  "description": "Installs/Configures the Apache Hadoop distribution",
  "long_description": "# Apache Hadoop cookbook\n\n[![Apache License 2.0](http://img.shields.io/badge/license-apache%202.0-green.svg)](http://opensource.org/licenses/Apache-2.0)\n\n# Requirements\n\nThis cookbook has been tested on the following versions (but may work on earlier ones):\n\n* Chef 12.3.0+\n* CentOS 7.0+\n* Ubuntu 14.04+\n\n\n####Recipes\n\n* `install.rb` - Installs the Apache Hadoop Binaries\n* `nn.rb` - Configures and starts the NameNode\n* `dn.rb` - Configures and starts the DataNode\n* `rm.rb` - Configures and starts the ResourceManager\n* `nm.rb` - Configures and starts the NodeManager\n* `jhs.rb`- Configures and starts the JobHistoryServer\n* `ps.rb` - Configures and starts the ProxyServer\n\n\n###Karamel usage\n\nThis cookbook is karamelized (www.karamel.io).  You can launch a Hadoop Cluster using the following yml file. It will create 3 VMs, where one is the master running NameNode, ResourceManager, and Job history server. The two other VMs are workers and will run the DataNode and NodeManager.\n\n```\nname: eu-west-1\n\ncookbooks:                                                                      \n  apache_hadoop: \n    github: \"hopshadoop/apache-hadoop-chef\"\n    tag: \"v0.1.0\"\n    \ngroups: \n  namenodes:\n    size: 1\n    recipes: \n        - apache_hadoop::nn\n        - apache_hadoop::rm\n        - apache_hadoop::jhs                                                            \n  datanodes:\n    size: 2\n    recipes: \n        - apache_hadoop::dn\n        - apache_hadoop::nm\n```\n\n\n# Authors\n\nAuthors:: Jim Dowling. (<jdowling@kth.se>), Marc Bux \n\n# License\n\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use this software except in compliance with the License. You may obtain a copy of the License at\n\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\n",
  "maintainer": "Jim Dowling",
  "maintainer_email": "jdowling@kth.se",
  "license": "GPL 2.0",
  "platforms": {
    "ubuntu": ">= 0.0.0",
    "debian": ">= 0.0.0",
    "rhel": ">= 0.0.0",
    "centos": ">= 0.0.0"
  },
  "dependencies": {
    "kagent": ">= 0.0.0",
    "java": ">= 0.0.0",
    "sysctl": ">= 0.0.0",
    "cmake": ">= 0.0.0"
  },
  "recommendations": {

  },
  "suggestions": {

  },
  "conflicting": {

  },
  "providing": {

  },
  "replacing": {

  },
  "attributes": {
    "java/jdk_version": {
      "description": "Jdk version",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "java/install_flavor": {
      "description": "Oracle (default) or openjdk",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/nm/memory_mbs": {
      "description": "Apache_Hadoop NodeManager Memory in MB",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/vcores": {
      "description": "Apache_Hadoop NodeManager Number of Virtual Cores",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/max_vcores": {
      "description": "Hadoop NodeManager Maximum Virtual Cores per container",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/version": {
      "description": "Version of apache_hadoop",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/num_replicas": {
      "description": "Number of replicates for each file stored in HDFS",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/container_cleanup_delay_sec": {
      "description": "The number of seconds container data is retained after termination",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/group": {
      "description": "Group to run hdfs/yarn/mr as",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/user": {
      "description": "Username to run yarn as",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/mr/user": {
      "description": "Username to run mapReduce as",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/hdfs/user": {
      "description": "Username to run hdfs as",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/format": {
      "description": "Format HDFS, Run 'hdfs namenode -format",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/tmp_dir": {
      "description": "The directory in which Hadoop stores temporary data, including container data",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/data_dir": {
      "description": "The directory in which Hadoop's DataNodes store their data",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/nodemanager_hb_ms": {
      "description": "Heartbeat Interval for NodeManager->ResourceManager in ms",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/rm/scheduler_class": {
      "description": "Java Classname for the Yarn scheduler (fifo, capacity, fair)",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/rm/scheduler_capacity/calculator_class": {
      "description": "Switch to DominantResourseCalculator for multiple resource scheduling",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/user_envs": {
      "description": "Update the PATH environment variable for the hdfs and yarn users to include hadoop/bin in the PATH ",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/logging_level": {
      "description": "Log levels are: TRACE, DEBUG, INFO, WARN",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/nn/heap_size": {
      "description": "Size of the NameNode heap in MBs",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/nn/direct_memory_size": {
      "description": "Size of the direct memory size for the NameNode in MBs",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/ha_enabled": {
      "description": "'true' to enable HA, else 'false'",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/yarn/rt": {
      "description": "Hadoop Resource Tracker enabled on this nodegroup",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    },
    "apache_hadoop/dir": {
      "description": "Hadoop installation directory",
      "type": "string",
      "choice": [

      ],
      "calculated": false,
      "required": "optional",
      "recipes": [

      ]
    }
  },
  "groupings": {

  },
  "recipes": {
    "apache_hadoop::nn": "Installs a Hadoop NameNode",
    "apache_hadoop::dn": "Installs a Hadoop DataNode",
    "apache_hadoop::rm": "Installs a YARN ResourceManager",
    "apache_hadoop::nm": "Installs a YARN NodeManager",
    "apache_hadoop::jhs": "Installs a MapReduce History Server for YARN",
    "apache_hadoop::ps": "Installs a WebProxy Server for YARN"
  },
  "version": "0.1.1",
  "source_url": "https://github.com/hopshadoop/apache-hadoop-chef",
  "issues_url": "",
  "privacy": false,
  "chef_versions": [

  ],
  "ohai_versions": [

  ],
  "gems": [

  ]
}
