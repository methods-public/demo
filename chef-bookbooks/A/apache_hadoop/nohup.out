-----> Starting Kitchen (v1.10.0)
-----> Cleaning up any prior instances of <default-ubuntu-1404>
-----> Destroying <default-ubuntu-1404>...
       Finished destroying <default-ubuntu-1404> (0m0.00s).
-----> Testing <default-ubuntu-1404>
-----> Creating <default-ubuntu-1404>...
       Bringing machine 'default' up with 'virtualbox' provider...
       ==> default: Importing base box 'bento/ubuntu-14.04'...
       [KProgress: 10%[KProgress: 20%[KProgress: 30%[KProgress: 40%[KProgress: 50%[KProgress: 60%[KProgress: 80%[KProgress: 90%[K==> default: Matching MAC address for NAT networking...
       ==> default: Checking if box 'bento/ubuntu-14.04' is up to date...
       ==> default: Setting the name of the VM: kitchen-apache-hadoop-chef-default-ubuntu-1404_default_1472158049734_44223
       ==> default: Fixed port collision for 22 => 2222. Now on port 2201.
       ==> default: Clearing any previously set network interfaces...
       ==> default: Preparing network interfaces based on configuration...
           default: Adapter 1: nat
       ==> default: Forwarding ports...
           default: 22 (guest) => 2201 (host) (adapter 1)
       ==> default: Running 'pre-boot' VM customizations...
       ==> default: Booting VM...
       ==> default: Waiting for machine to boot. This may take a few minutes...
           default: SSH address: 127.0.0.1:2201
           default: SSH username: vagrant
           default: SSH auth method: private key
           default: 
           default: Vagrant insecure key detected. Vagrant will automatically replace
           default: this with a newly generated keypair for better security.
           default: 
           default: Inserting generated public key within guest...
           default: Removing insecure key from the guest if it's present...
           default: Key inserted! Disconnecting and reconnecting using new SSH key...
       ==> default: Machine booted and ready!
       ==> default: Checking for guest additions in VM...
           default: The guest additions on this VM do not match the installed version of
           default: VirtualBox! In most cases this is fine, but in rare cases it can
           default: prevent things such as shared folders from working properly. If you see
           default: shared folder errors, please make sure the guest additions within the
           default: virtual machine match the version of VirtualBox you have installed on
           default: your host and reload your VM.
           default: 
           default: Guest Additions Version: 5.0.26
           default: VirtualBox Version: 4.3
       ==> default: Setting hostname...
       ==> default: Machine not provisioned because `--no-provision` is specified.
       [SSH] Established
       Vagrant instance <default-ubuntu-1404> created.
       Finished creating <default-ubuntu-1404> (0m54.28s).
-----> Converging <default-ubuntu-1404>...
       Preparing files for transfer
       Preparing dna.json
       Resolving cookbook dependencies with Berkshelf 4.3.5...
       Removing non-cookbook files before transfer
       Preparing solo.rb
-----> Installing Chef Omnibus (install only if missing)
       Downloading https://omnitruck.chef.io/install.sh to file /tmp/install.sh
       Trying wget...
       Download complete.
       ubuntu 14.04 x86_64
       Getting information for chef stable  for ubuntu...
       downloading https://omnitruck.chef.io/stable/chef/metadata?v=&p=ubuntu&pv=14.04&m=x86_64
         to file /tmp/install.sh.1129/metadata.txt
       trying wget...
       sha1	72a0a10ba5684d1e51590c1bc022bcb2e99348c6
       sha256	973c2bc9a84822158ba7c0c360d0a25c97420f293ccbe5d8019615a411460785
       url	https://packages.chef.io/stable/ubuntu/14.04/chef_12.13.37-1_amd64.deb
       version	12.13.37
       downloaded metadata file looks valid...
       downloading https://packages.chef.io/stable/ubuntu/14.04/chef_12.13.37-1_amd64.deb
         to file /tmp/install.sh.1129/chef_12.13.37-1_amd64.deb
       trying wget...
       Comparing checksum with sha256sum...
       
       WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING
       
       You are installing an omnibus package without a version pin.  If you are installing
       on production servers via an automated process this is DANGEROUS and you will
       be upgraded without warning on new releases, even to new major releases.
       Letting the version float is only appropriate in desktop, test, development or
       CI/CD environments.
       
       WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING
       
       Installing chef 
       installing with dpkg...
       Selecting previously unselected package chef.
       (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 32949 files and directories currently installed.)
       Preparing to unpack .../chef_12.13.37-1_amd64.deb ...
       Unpacking chef (12.13.37-1) ...
       Setting up chef (12.13.37-1) ...
       Thank you for installing Chef!
       Transferring files to <default-ubuntu-1404>
       Starting Chef Client, version 12.13.37
       Creating a new client identity for default-ubuntu-1404 using the validator key.
       resolving cookbooks for run list: ["kagent::install", "apache_hadoop::install", "apache_hadoop::nn", "apache_hadoop::dn", "apache_hadoop::rm", "apache_hadoop::nm", "apache_hadoop::jhs"]
       Synchronizing Cookbooks:
         - kagent (0.1.2)
         - apache_hadoop (0.1.0)
         - python (1.4.6)
         - java (1.39.0)
         - hostsfile (2.4.5)
         - cmake (0.3.0)
         - sysctl (0.7.5)
         - seven_zip (2.0.0)
         - build-essential (3.2.0)
         - yum-epel (0.7.0)
         - apt (3.0.0)
         - ohai (3.0.1)
         - yum (3.10.0)
         - windows (1.40.0)
         - chef_handler (1.3.0)
       Installing Cookbook Gems:
       Compiling Cookbooks...
       [2016-08-25T20:59:42+00:00] WARN: Chef::Provider::AptRepository already exists!  Cannot create deprecation class for LWRP provider apt_repository from cookbook apt
       [2016-08-25T20:59:42+00:00] WARN: AptRepository already exists!  Deprecation class overwrites Custom resource apt_repository from cookbook apt
       
       ================================================================================
       Recipe Compile Error in /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb
       ================================================================================
       
       NoMethodError
       -------------
       Undefined method or attribute `enabled' on `node'
       
       Cookbook Trace:
       ---------------
         /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:147:in `from_file'
       
       Relevant File Content:
       ----------------------
       /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:
       
       140:      notifies :enable, resources(:service => "#{service_name}")
       141:      notifies :restart, resources(:service => "#{service_name}"), :immediately
       142:    end 
       143:  end
       144:  
       145:  
       146:  
       147>> if node.kagent.enabled == "true" 
       148:    kagent_config "#{service_name}" do
       149:      service "HDFS"
       150:      config_file "#{node.apache_hadoop.conf_dir}/hdfs-site.xml"
       151:      log_file "#{node.apache_hadoop.logs_dir}/hadoop-#{node.apache_hadoop.hdfs.user}-#{service_name}-#{node.hostname}.out"
       152:      web_port node.apache_hadoop.nn.http_port
       153:    end
       154:  end
       155:  
       156:  tmp_dirs   = [ "/tmp", node.apache_hadoop.hdfs.user_home, node.apache_hadoop.hdfs.user_home + "/" + node.apache_hadoop.hdfs.user ]
       
       Platform:
       ---------
       x86_64-linux
       
       
       Running handlers:
       [2016-08-25T20:59:52+00:00] ERROR: Running exception handlers
       Running handlers complete
       [2016-08-25T20:59:52+00:00] ERROR: Exception handlers complete
       Chef Client failed. 0 resources updated in 22 seconds
       [2016-08-25T20:59:52+00:00] FATAL: Stacktrace dumped to /tmp/kitchen/cache/chef-stacktrace.out
       [2016-08-25T20:59:52+00:00] FATAL: Please provide the contents of the stacktrace.out file if you file a bug report
       [2016-08-25T20:59:52+00:00] ERROR: Undefined method or attribute `enabled' on `node'
       [2016-08-25T20:59:54+00:00] FATAL: Chef::Exceptions::ChildConvergeError: Chef run process exited unsuccessfully (exit code 1)
-----> Cleaning up any prior instances of <default-centos-70>
-----> Destroying <default-centos-70>...
       Finished destroying <default-centos-70> (0m0.00s).
-----> Testing <default-centos-70>
-----> Creating <default-centos-70>...
       Bringing machine 'default' up with 'virtualbox' provider...
       ==> default: Box 'bento/centos-7.0' could not be found. Attempting to find and install...
           default: Box Provider: virtualbox
           default: Box Version: >= 0
       The box 'bento/centos-7.0' could not be found or
       could not be accessed in the remote catalog. If this is a private
       box on HashiCorp's Atlas, please verify you're logged in via
       `vagrant login`. Also, please double-check the name. The expanded
       URL and error message are shown below:
       
       URL: ["https://atlas.hashicorp.com/bento/centos-7.0"]
       Error: The requested URL returned error: 404 Not Found
>>>>>> ------Exception-------
>>>>>> Class: Kitchen::ActionFailed
>>>>>> Message: 2 actions failed.
>>>>>>     Converge failed on instance <default-ubuntu-1404>.  Please see .kitchen/logs/default-ubuntu-1404.log for more details
>>>>>>     Failed to complete #create action: [Expected process to exit with [0], but received '1'
---- Begin output of vagrant up --no-provision --provider virtualbox ----
STDOUT: Bringing machine 'default' up with 'virtualbox' provider...
==> default: Box 'bento/centos-7.0' could not be found. Attempting to find and install...
    default: Box Provider: virtualbox
    default: Box Version: >= 0
STDERR: The box 'bento/centos-7.0' could not be found or
could not be accessed in the remote catalog. If this is a private
box on HashiCorp's Atlas, please verify you're logged in via
`vagrant login`. Also, please double-check the name. The expanded
URL and error message are shown below:

URL: ["https://atlas.hashicorp.com/bento/centos-7.0"]
Error: The requested URL returned error: 404 Not Found
---- End output of vagrant up --no-provision --provider virtualbox ----
Ran vagrant up --no-provision --provider virtualbox returned 1] on default-centos-70
>>>>>> ----------------------
>>>>>> Please see .kitchen/logs/kitchen.log for more details
>>>>>> Also try running `kitchen diagnose --all` for configuration
-----> Starting Kitchen (v1.10.0)
-----> Creating <default-ubuntu-1404>...
       Bringing machine 'default' up with 'virtualbox' provider...
       ==> default: Importing base box 'bento/ubuntu-14.04'...
       [KProgress: 10%[KProgress: 20%[KProgress: 30%[KProgress: 40%[KProgress: 50%[KProgress: 60%[KProgress: 80%[KProgress: 90%[K==> default: Matching MAC address for NAT networking...
       ==> default: Checking if box 'bento/ubuntu-14.04' is up to date...
       ==> default: Setting the name of the VM: kitchen-apache-hadoop-chef-default-ubuntu-1404_default_1472220661319_32989
       ==> default: Fixed port collision for 22 => 2222. Now on port 2200.
       ==> default: Clearing any previously set network interfaces...
       ==> default: Preparing network interfaces based on configuration...
           default: Adapter 1: nat
       ==> default: Forwarding ports...
           default: 22 (guest) => 2200 (host) (adapter 1)
       ==> default: Running 'pre-boot' VM customizations...
       ==> default: Booting VM...
       ==> default: Waiting for machine to boot. This may take a few minutes...
           default: SSH address: 127.0.0.1:2200
           default: SSH username: vagrant
           default: SSH auth method: private key
           default: 
           default: Vagrant insecure key detected. Vagrant will automatically replace
           default: this with a newly generated keypair for better security.
           default: 
           default: Inserting generated public key within guest...
           default: Removing insecure key from the guest if it's present...
           default: Key inserted! Disconnecting and reconnecting using new SSH key...
       ==> default: Machine booted and ready!
       ==> default: Checking for guest additions in VM...
           default: The guest additions on this VM do not match the installed version of
           default: VirtualBox! In most cases this is fine, but in rare cases it can
           default: prevent things such as shared folders from working properly. If you see
           default: shared folder errors, please make sure the guest additions within the
           default: virtual machine match the version of VirtualBox you have installed on
           default: your host and reload your VM.
           default: 
           default: Guest Additions Version: 5.0.26
           default: VirtualBox Version: 4.3
       ==> default: Setting hostname...
       ==> default: Machine not provisioned because `--no-provision` is specified.
       [SSH] Established
       Vagrant instance <default-ubuntu-1404> created.
       Finished creating <default-ubuntu-1404> (0m56.45s).
-----> Converging <default-ubuntu-1404>...
       Preparing files for transfer
       Preparing dna.json
       Resolving cookbook dependencies with Berkshelf 4.3.5...
       Removing non-cookbook files before transfer
       Preparing solo.rb
-----> Installing Chef Omnibus (install only if missing)
       Downloading https://omnitruck.chef.io/install.sh to file /tmp/install.sh
       Trying wget...
       Download complete.
       ubuntu 14.04 x86_64
       Getting information for chef stable  for ubuntu...
       downloading https://omnitruck.chef.io/stable/chef/metadata?v=&p=ubuntu&pv=14.04&m=x86_64
         to file /tmp/install.sh.1128/metadata.txt
       trying wget...
       sha1	72a0a10ba5684d1e51590c1bc022bcb2e99348c6
       sha256	973c2bc9a84822158ba7c0c360d0a25c97420f293ccbe5d8019615a411460785
       url	https://packages.chef.io/stable/ubuntu/14.04/chef_12.13.37-1_amd64.deb
       version	12.13.37
       downloaded metadata file looks valid...
       downloading https://packages.chef.io/stable/ubuntu/14.04/chef_12.13.37-1_amd64.deb
         to file /tmp/install.sh.1128/chef_12.13.37-1_amd64.deb
       trying wget...
       Comparing checksum with sha256sum...
       
       WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING
       
       You are installing an omnibus package without a version pin.  If you are installing
       on production servers via an automated process this is DANGEROUS and you will
       be upgraded without warning on new releases, even to new major releases.
       Letting the version float is only appropriate in desktop, test, development or
       CI/CD environments.
       
       WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING WARNING
       
       Installing chef 
       installing with dpkg...
       Selecting previously unselected package chef.
       (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 32949 files and directories currently installed.)
       Preparing to unpack .../chef_12.13.37-1_amd64.deb ...
       Unpacking chef (12.13.37-1) ...
       Setting up chef (12.13.37-1) ...
       Thank you for installing Chef!
       Transferring files to <default-ubuntu-1404>
       Starting Chef Client, version 12.13.37
       Creating a new client identity for default-ubuntu-1404 using the validator key.
       resolving cookbooks for run list: ["kagent::install", "apache_hadoop::install", "apache_hadoop::nn", "apache_hadoop::dn", "apache_hadoop::rm", "apache_hadoop::nm", "apache_hadoop::jhs"]
       Synchronizing Cookbooks:
         - kagent (0.1.2)
         - apache_hadoop (0.1.0)
         - poise-python (1.4.0)
         - sudo (2.11.0)
         - hostsfile (2.4.5)
         - openssl (4.4.0)
         - java (1.42.0)
         - cmake (0.3.0)
         - sysctl (0.7.0)
         - ntp (2.0.0)
         - poise (2.7.1)
         - poise-languages (1.4.0)
         - chef-sugar (3.4.0)
         - windows (1.44.3)
         - poise-archive (1.3.0)
         - homebrew (2.1.0)
         - ohai (4.2.0)
         - apt (4.0.2)
         - chef_handler (1.4.0)
         - compat_resource (12.13.38)
         - seven_zip (2.0.1)
         - build-essential (6.0.4)
         - mingw (1.2.4)
       Installing Cookbook Gems:
       Compiling Cookbooks...
       [2016-08-26T14:14:32+00:00] WARN: Chef::Provider::AptRepository already exists!  Cannot create deprecation class for LWRP provider apt_repository from cookbook apt
       [2016-08-26T14:14:32+00:00] WARN: AptRepository already exists!  Deprecation class overwrites Custom resource apt_repository from cookbook apt
       Converging 150 resources
       Recipe: kagent::install
         * bash[apt_update_install_build_tools] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-687vg6"
       Recipe: poise-python::default
         * python_runtime[2] action install
           * poise_languages_system[python2.7] action install
             - install version 2.7.6-8ubuntu0.2 of package python2.7-dev
         
         * python_runtime_pip[2] action install
           - Bootstrapping pip latest from https://bootstrap.pypa.io/get-pip.py
         * python_package[setuptools] action install
           - install version 26.0.0 of package setuptools
         * python_package[wheel] action install
           - install version 0.29.0 of package wheel
         * python_package[virtualenv] action install
           - install version 15.0.3 of package virtualenv
       
       Recipe: kagent::install
         * group[kagent] action create
           - create group kagent
         * group[certs] action create
           - create group certs
         * user[kagent] action create
           - create user kagent
         * group[kagent] action modify
           - modify group kagent
           - add missing member(s): kagent
         * group[certs] action modify
           - modify group certs
           - add missing member(s): kagent
         * cookbook_file[/tmp/inifile-2.0.2.gem] action create_if_missing
           - create new file /tmp/inifile-2.0.2.gem
           - update content in file /tmp/inifile-2.0.2.gem from none to 454c96
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/requests-1.0.3.tar.gz] action create_if_missing
           - create new file /tmp/requests-1.0.3.tar.gz
           - update content in file /tmp/requests-1.0.3.tar.gz from none to c7b50d
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/bottle-0.11.4.tar.gz] action create_if_missing
           - create new file /tmp/bottle-0.11.4.tar.gz
           - update content in file /tmp/bottle-0.11.4.tar.gz from none to ec21d1
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/CherryPy-3.2.2.tar.gz] action create
           - create new file /tmp/CherryPy-3.2.2.tar.gz
           - update content in file /tmp/CherryPy-3.2.2.tar.gz from none to dc5a88
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/pyOpenSSL-0.13.tar.gz] action create_if_missing
           - create new file /tmp/pyOpenSSL-0.13.tar.gz
           - update content in file /tmp/pyOpenSSL-0.13.tar.gz from none to 21e12b
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * apt_package[python-mysqldb] action install
           - install version 1.2.3-2ubuntu1 of package python-mysqldb
         * cookbook_file[/tmp/netifaces-0.8.tar.gz] action create_if_missing
           - create new file /tmp/netifaces-0.8.tar.gz
           - update content in file /tmp/netifaces-0.8.tar.gz from none to 53a711
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/IPy-0.81.tar.gz] action create_if_missing
           - create new file /tmp/IPy-0.81.tar.gz
           - update content in file /tmp/IPy-0.81.tar.gz from none to 4bc17a
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * cookbook_file[/tmp/pexpect-2.3.tar.gz] action create_if_missing
           - create new file /tmp/pexpect-2.3.tar.gz
           - update content in file /tmp/pexpect-2.3.tar.gz from none to d315e7
           (new content is binary, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * bash[install_python] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-vj4vpi"
         * bash[make_gemrc_file] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1mls00c"
         * gem_package[inifile] action install
           - install version 2.0.2 of package inifile
         * directory[/var/lib/kagent-0.1.0] action create
           - create new directory /var/lib/kagent-0.1.0
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * directory[/var/lib/kagent-certs] action create
           - create new directory /var/lib/kagent-certs
           - change mode from '' to '0750'
           - change owner from '' to 'kagent'
           - change group from '' to 'certs'
         * link[/var/lib/kagent] action delete (skipped due to only_if)
         * link[/var/lib/kagent] action create
           - create symlink at /var/lib/kagent to /var/lib/kagent-0.1.0
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * directory[/var/lib/kagent/bin] action create
           - create new directory /var/lib/kagent/bin
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * directory[/var/lib/kagent-certs/keystores] action create
           - create new directory /var/lib/kagent-certs/keystores
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * file[/var/lib/kagent/services] action create_if_missing
           - create new file /var/lib/kagent/services
           - change mode from '' to '0755'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * hostsfile_entry[10.0.2.15] action create
         Recipe: <Dynamically Defined Resource>
           * file[/etc/hosts] action create
             - update content in file /etc/hosts from d3a30b to 57c971
             --- /etc/hosts	2016-08-26 14:13:35.944308046 +0000
             +++ /etc/.chef-hosts20160826-1220-1jfyk6m	2016-08-26 14:16:03.242132738 +0000
             @@ -1,7 +1,16 @@
             -127.0.0.1	default-ubuntu-1404	default-ubuntu-1404
             +#
             +# This file is managed by Chef, using the hostsfile cookbook.
             +# Editing this file by hand is highly discouraged!
             +#
             +# Comments containing an @ sign should not be modified or else
             +# hostsfile will be unable to guarantee relative priority in
             +# future Chef runs!
             +#
             +
       127.0.0.1	localhost
             -127.0.1.1	vagrant.vm	vagrant
             -::1     localhost ip6-localhost ip6-loopback
             -ff02::1 ip6-allnodes
             -ff02::2 ip6-allrouters
             +127.0.1.1	vagrant.vm vagrant
             +10.0.2.15	default-ubuntu-1404
             +ff02::1	ip6-allnodes
             +ff02::2	ip6-allrouters
             +::1	localhost ip6-localhost ip6-loopback
           - Create hostsfile_entry[10.0.2.15]
       Recipe: kagent::install
         * hostsfile_entry[10.0.2.15] action create (up to date)
         * template[/var/lib/kagent/agent.py] action create
           - create new file /var/lib/kagent/agent.py
           - update content in file /var/lib/kagent/agent.py from none to 15483c
           --- /var/lib/kagent/agent.py	2016-08-26 14:16:03.250128739 +0000
           +++ /var/lib/kagent/.chef-agent.py20160826-1220-facyn	2016-08-26 14:16:03.250128739 +0000
           @@ -1 +1,866 @@
           +#!/usr/bin/env python
           +
           +'''
           +Created on 6 October 2013
           +
           +@author: Hamidreza Afzali <afzali@kth.se>
           +@author: Jim Dowling <jdowling@kth.se>
           +
           +Install:
           + requests:    easy_install requests
           + bottle:      easy_install bottle
           + Cherrypy:    easy_install cherrypy
           + Netifaces:   easy_install netifaces
           + IPy:         easy_install ipy
           + pyOpenSSL:   apt-get install python-openssl 
           + MySQLdb:     apt-get install python-mysqldb
           + pexpect:     apt-get install python-pexpect
           +'''
           +
           +import time
           +from time import sleep
           +from datetime import datetime
           +import multiprocessing
           +import thread
           +from threading import Lock
           +import threading
           +import subprocess
           +from subprocess import Popen
           +import os
           +import sys
           +import ConfigParser
           +import requests
           +import logging.handlers
           +import json 
           +from OpenSSL import crypto
           +import socket
           +from os.path import exists, join
           +import MySQLdb
           +from bottle import Bottle, run, get, post, request, HTTPResponse, server_names, ServerAdapter
           +import netifaces 
           +from IPy import IP
           +import pexpect
           +import re
           +
           +global mysql_process
           +mysql_process = None
           +var="~#@#@!#@!#!@#@!#"
           +
           +config_mutex = Lock()
           +
           +HTTP_OK = 200
           +
           +BIN_DIR = "/var/lib/kagent/bin"
           +CONFIG_FILE = "/var/lib/kagent/config.ini"
           +SERVICES_FILE = "/var/lib/kagent/services"
           +LOG_FILE = "/var/lib/kagent/agent.log"
           +
           +CERT_FILE = "/var/lib/kagent-certs/pub.pem"
           +CA_FILE = "/var/lib/kagent-certs/ca_pub.pem"
           +KEY_FILE = "/var/lib/kagent-certs/priv.key"
           +SERVER_KEYSTORE = "/var/lib/kagent-certs/keystores/node_server_keystore.jks"
           +SERVER_TRUSTSTORE = "/var/lib/kagent-certs/keystores/node_server_truststore.jks"
           +CLIENT_TRUSTSTORE = "/var/lib/kagent-certs/keystores/node_client_truststore.jks"
           +
           +global states
           +states = {}
           +
           +cores = multiprocessing.cpu_count()
           +
           +# reading config
           +try:
           +    config = ConfigParser.ConfigParser()
           +    config.read(CONFIG_FILE)
           +    server_url = config.get('server', 'url')
           +    login_url = server_url + config.get('server', 'path-login')
           +    register_url = server_url + config.get('server', 'path-register')
           +    heartbeat_url = server_url + config.get('server', 'path-heartbeat')
           +    alert_url = server_url + config.get('server', 'path-alert')
           +            
           +    server_username = config.get('server', 'username')
           +    server_password = config.get('server', 'password')
           +    
           +    logging_level = config.get('agent', 'logging-level').upper()
           +    max_log_size = config.getint('agent', 'max-log-size')    
           +    user = config.get('agent', 'username')
           +    password = config.get('agent', 'password')          
           +    agent_pidfile = config.get('agent', 'pid-file')
           +    agent_restport = config.getint('agent', 'restport')
           +    heartbeat_interval = config.getfloat('agent', 'heartbeat-interval')
           +    watch_interval = config.getfloat('agent', 'watch-interval')
           +    mysql_socket = config.get('agent', 'mysql-socket')          
           +    network_interface = config.get('agent', 'network-interface')          
           +    group_name = config.get('agent', 'group-name')          
           +
           +# TODO find public/private IP addresses 
           +    public_ip = None
           +    private_ip = None 
           +    eth0_ip = netifaces.ifaddresses(network_interface)[netifaces.AF_INET][0]['addr'] 
           +    if (IP(eth0_ip).iptype() == "PUBLIC"):
           +        public_ip = eth0_ip
           +    else:
           +        private_ip = eth0_ip
           +    
           +    if (config.has_option("agent", "hostname")):
           +        hostname = config.get("agent", "hostname")
           +    else:
           +        hostname = socket.gethostbyaddr(eth0_ip)[0]
           +        
           +    if (config.has_option("agent", "host-id")):
           +        host_id = config.get("agent", "host-id")
           +    else:
           +        host_id = hostname
           +
           +    
           +except Exception, e:
           +    print "Exception while reading {0}: {1}".format(CONFIG_FILE, e)
           +    sys.exit(1)
           +
           +# logging
           +try:
           +    os.remove(LOG_FILE + '.1')
           +except:
           +    pass    
           +with open(LOG_FILE, 'w'):  # clear log file
           +    pass
           +logger = logging.getLogger('agent')
           +logger_formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
           +logger_file_handler = logging.handlers.RotatingFileHandler(LOG_FILE, "w", maxBytes=max_log_size, backupCount=1)
           +logger_stream_handler = logging.StreamHandler()
           +logger_file_handler.setFormatter(logger_formatter)
           +logger_stream_handler.setFormatter(logger_formatter)
           +logger.addHandler(logger_file_handler)
           +logger.addHandler(logger_stream_handler)
           +logger.setLevel(logging.INFO)
           +
           +logger.info("Hops-Kagent started.")
           +logger.info("Heartbeat URL: {0}".format(heartbeat_url))
           +logger.info("Alert URL: {0}".format(alert_url))
           +logger.info("Host Id: {0}".format(host_id))
           +logger.info("Hostname: {0}".format(hostname))
           +logger.info("Public IP: {0}".format(public_ip))
           +logger.info("Private IP: {0}".format(private_ip))
           +
           +verbose=False
           +
           +# reading services
           +try:
           +    services = ConfigParser.ConfigParser()
           +    services.read(SERVICES_FILE)
           +
           +    for s in services.sections():
           +        if services.has_option(s, "role") :        
           +            states[services.get(s, "role")] = {'status':'Stopped', 'start-time':''}
           +
           +except Exception, e:
           +    logger.error("Exception while reading {0} file: {1}".format(SERVICES_FILE, e))
           +    sys.exit(1)     
           +
           +loggedIn = False
           + 
           +class Util():
           +    
           +    def logging_level(self, level):
           +        return {
           +                'INFO': logging.INFO,
           +                'WARN': logging.WARN,
           +                'WARNING': logging.WARNING,
           +                'ERROR': logging.ERROR,
           +                'DEBUG' : logging.DEBUG,
           +                'CRITICAL': logging.CRITICAL,
           +                }.get(level, logging.NOTSET)
           +
           +    @staticmethod
           +    def tail(file_name, n):
           +        stdin, stdout = os.popen2("tail -n {0} {1}".format(n, file_name))
           +        stdin.close()
           +        lines = stdout.readlines(); 
           +        stdout.close()
           +        log = "".join(str(x) for x in lines)
           +        return log
           +
           +
           +class Heartbeat():
           +    daemon_threads = True 
           +    def __init__(self):
           +        while True:    
           +            Heartbeat.send()
           +            time.sleep(heartbeat_interval) 
           +
           +
           +    @staticmethod
           +    def login():
           +        json_headers = {'User-Agent': 'Agent', 'content-type': 'application/json'}
           +        form_headers = {'User-Agent': 'Agent', 'content-type': 'application/x-www-form-urlencoded'}
           +        payload = {}
           +        global loggedIn
           +        global session
           +        try:
           +            session = requests.Session()
           +            resp = session.post(login_url, data={'email': server_username, 'password': server_password}, headers=form_headers, verify=False)
           +#            resp = session.put(register_url, data=json.dumps(payload), headers=json_headers, verify=False)
           +            if not resp.status_code == HTTP_OK:
           +                loggedIn = False
           +                logger.warn('Could not login agent to Hopsworks (Status code: {0}).'.format(resp.status_code))
           +            else:
           +                logger.info('Successful login of agent to Hopsworks (Status code: {0}).'.format(resp.status_code))
           +                loggedIn = True
           +        except Exception as err:
           +            logger.warn('Could not login agent to Hopsworks {0}'.format(err))
           +            loggedIn = False
           +
           +    @staticmethod
           +    def serviceKey(*keys):
           +            ob = states
           +            for key in keys:
           +                ob = ob[key]
           +            return ob
           +
           +    @staticmethod
           +    def send():
           +        global loggedIn
           +        global session
           +        if not loggedIn:
           +           logger.info('Logging in to Hopsworks....')
           +           Heartbeat.login()
           +        else:
           +            try:
           +                disk_info = DiskInfo() 
           +                memory_info = MemoryInfo()
           +                load_info = LoadInfo()
           +                services_list = Config().read_all_for_heartbeat()
           +                now = long(time.mktime(datetime.now().timetuple()))                
           +                headers = {'content-type': 'application/json'}
           +                payload = {}
           +                payload["host-id"] = host_id            
           +                payload["agent-time"] = now
           +                payload["load1"] = load_info.load1
           +                payload["load5"] = load_info.load5
           +                payload["load15"] = load_info.load15
           +                payload["disk-used"] = disk_info.used
           +                payload['memory-used'] = memory_info.used - memory_info.cached - memory_info.buffers
           +                payload["services"] = services_list            
           +                payload["group-name"] = group_name
           +                payload["hostname"] = hostname
           +
           +                if (public_ip != None):
           +                    payload["public-ip"] = public_ip                      
           +                else:
           +                    payload["public-ip"] = ""
           +
           +                if (private_ip != None):
           +                    payload["private-ip"] = private_ip 
           +                else:
           +                    payload["private-ip"] = ""
           +
           +                payload["cores"] = cores
           +                payload["disk-capacity"] = disk_info.capacity    
           +                payload['memory-capacity'] = memory_info.total                            
           +                logger.info("Sending heartbeat...")
           +                resp = session.post(heartbeat_url, data=json.dumps(payload), headers=headers, verify=False)
           +                if not resp.status_code == HTTP_OK:
           +                    raise Exception('Heartbeat could not be sent (Status code: {0})'.format(resp.status_code))
           +                    loggedIn = False
           +            except Exception as err:
           +                logger.error("{0}. Retrying in {1} seconds...".format(err, heartbeat_interval))
           +                loggedIn = False
           +
           +
           +class Alert:
           +    @staticmethod    
           +    def send(cluster, service, role, time, status):
           +        global session
           +        try:
           +            headers = {'content-type': 'application/json'}
           +            payload = {}
           +            payload["Provider"] = "Agent"            
           +            payload["host-id"] = host_id
           +            payload["Time"] = time
           +            payload["Plugin"] = "Monitoring"
           +            payload["Type"] = "Role"
           +            payload["TypeInstance"] = "{0}/{1}/{2}".format(cluster, service, role)
           +            payload["DataSource"] = "Agent"
           +            payload["CurrentValue"] = status
           +            if status == True:
           +                payload["Severity"] = "OK"
           +                payload["Message"] = "Role is running: {0}/{1}/{2}".format(cluster, service, role)
           +            else:
           +                payload["Severity"] = "FAILURE"
           +                payload["Message"] = "Role is not running: {0}/{1}/{2}".format(cluster, service, role)
           +            
           +            logger.info("Sending Alert...")
           +            auth = (server_username, server_password)
           +#            session = requests.Session()
           +#            session.post(alert_url, data=json.dumps(payload), headers=headers, auth=auth, verify=False)        
           +            requests.post(alert_url, data=json.dumps(payload), headers=headers, auth=auth, verify=False)        
           +        except:
           +            logger.error("Cannot access the REST service for alerts. Alert not sent.")
           +
           +            
           +class MemoryInfo(object):
           +    def __init__(self):
           +        process = subprocess.Popen("free", shell=True, stdout=subprocess.PIPE)
           +        stdout_list = process.communicate()[0].split('\n')
           +        for line in stdout_list:
           +            data = line.split()
           +            try:
           +                if data[0] == "Mem:":
           +                    self.total = int(data[1]) * 1024
           +                    self.used = int(data[2]) * 1024
           +                    self.free = int(data[3]) * 1024
           +                    self.buffers = int(data[5]) * 1024
           +                    self.cached = int(data[6]) * 1024
           +                    break
           +            except IndexError:
           +                continue
           +
           +
           +class DiskInfo(object):
           +    def __init__(self):
           +        disk = os.statvfs("/")
           +        self.capacity = disk.f_bsize * disk.f_blocks
           +        self.used = disk.f_bsize * (disk.f_blocks - disk.f_bavail)
           +
           +
           +class LoadInfo(object):
           +    def __init__(self):
           +        self.load1 = os.getloadavg()[0]
           +        self.load5 = os.getloadavg()[1]
           +        self.load15 = os.getloadavg()[2]
           +        
           +
           +class ExtProcess():  # external process
           +        
           +    @staticmethod        
           +    def watch(cluster, service, role):
           +        while True:
           +            try:
           +                section = Config().section_name(cluster, service, role)
           +                if Service().alive(cluster,service,role) == True:
           +                     if (states[role]['status'] == 'Stopped'):
           +                       logger.info("Process started: {0}/{1}/{2}".format(cluster, service, role))
           +                       Service().started(cluster, service, role)
           +                else:
           +                    raise Exception("Process is not running for {0}/{1}/{2}".format(cluster, service, role))
           +            except:  
           +                logger.warn("Proccess.watch: Process is not running: {0}/{1}/{2}".format(cluster, service, role))
           +                if (states[role]['status'] == 'Started'):
           +                    logger.info("Process failed: {0}/{1}/{2}".format(cluster, service, role))
           +                    Service().failed(cluster, service, role)
           +            sleep(watch_interval)
           +
           +class Config(): 
           +
           +    def section_name(self, cluster, service, role=None):
           +        if role == None:
           +            return "{0}-{1}".format(cluster, service)
           +        else:
           +            return "{0}-{1}-{2}".format(cluster, service, role)   
           +        
           +    # select items so that the key does not contain 'file' or 'script'
           +    def read_all_for_heartbeat(self):
           +        config_mutex.acquire()       
           +        services_list = []     
           +        try:
           +            for s in services.sections():
           +                   item = {}
           +                   item['status'] = Heartbeat.serviceKey(services.get(s, "role"), 'status')
           +                   services_list.append(item)   
           +                   for key, val in services.items(s):
           +                       if (not 'file' in key) and (not 'script' in key) and (not 'command' in key):
           +                           item[key] = val
           +                       services_list.append(item)                
           +        finally:
           +            config_mutex.release()
           +        return services_list
           +        
           +    def get_section(self, section):
           +        config_mutex.acquire()
           +        items = {}
           +        try:
           +            for key, val in services.items(section):
           +                items[key] = val
           +        finally:
           +            config_mutex.release()
           +        return items
           +    
           +    def get(self, section, option):
           +        config_mutex.acquire()
           +        val = ""
           +        try:         
           +            val = services.get(section, option)
           +        finally:
           +            config_mutex.release()
           +        return val                
           +
           +     
           +class Service:
           +    
           +    # need to be completed. Set the status to Initialize?
           +    def init(self, cluster, service, role):
           +        section = Config().section_name(cluster, service, role)
           +        script = Config().get(section, "init-script")
           +        try:
           +            p = Popen(script, shell=True, close_fds=True)
           +            p.wait()
           +            returncode = p.returncode
           +            if not returncode == 0:
           +                raise Exception("Init script returned a none-zero value")
           +            return True
           +        except Exception as err:
           +            logger.error(err)
           +            return False
           +
           +            
           +    def start(self, cluster, service, role):
           +        script = BIN_DIR + "/start-service.sh"
           +        try:
           +            p = Popen(['sudo',script,role],stdout=subprocess.PIPE, stderr=subprocess.PIPE)
           +            (output,err)=p.communicate()
           +            returncode = p.wait()
           +            logger.info("{0}".format(output))
           +            if not returncode == 0:
           +                raise Exception("Start script returned a none-zero value")
           +            Service().started(cluster, service, role)
           +            # wait for the alert to get returned to Hopsworks, before returning (as this will cause a correct refresh of the service's status)
           +            sleep(heartbeat_interval+1)
           +            return True
           +        except Exception as err:
           +            logger.error(err)
           +            return False
           +        
           +    def stop(self, cluster, service, role):
           +        script = BIN_DIR + "/stop-service.sh"
           +        try:
           +            subprocess.check_call(['sudo', script, role], close_fds=True)  # raises exception if not returncode == 0
           +            now = long(time.mktime(datetime.now().timetuple()))
           +            states[role] = {'status':'Stopped', 'stop-time':now}
           +            # wait for the alert to get returned to Hopsworks, before returning (as this will cause a correct refresh of the service's status)
           +            Service().failed(cluster, service, role)
           +            sleep(heartbeat_interval+1)
           +            return True
           +        except Exception as err:
           +            logger.error(err)
           +            return False
           +
           +    def restart(self, cluster, service, role):
           +        script = BIN_DIR + "/restart-service.sh"
           +        try:
           +            p = Popen(['sudo',script,role], close_fds=True)
           +            p.wait()
           +            returncode = p.returncode
           +            if not returncode == 0:
           +                raise Exception("Restart script returned a none-zero value")
           +            Service().started(cluster, service, role)
           +            # wait for the alert to get returned to Hopsworks, before returning (as this will cause a correct refresh of the service's status)
           +            sleep(heartbeat_interval)
           +            return True
           +        except Exception as err:
           +            logger.error(err)
           +            return False
           +
           +    def alive(self, cluster, service, role):
           +        script = BIN_DIR + "/status-service.sh"
           +        try:
           +            p = Popen(['sudo',script,role], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
           +            if (verbose == True):
           +                with p.stdout:
           +                    for line in iter(p.stdout.readline, b''):
           +                        logger.info("{0}".format(line))
           +            p.wait()
           +            if not p.returncode == 0:
           +                return False
           +        except Exception as err:
           +            logger.error(err)
           +            return False
           +        return True
           +
           +    def failed(self, cluster, service, role):
           +        now = long(time.mktime(datetime.now().timetuple()))
           +        states[role] = {'status':'Stopped', 'start-time':now}
           +        Alert.send(cluster, service, role, now, False)
           +
           +    def started(self, cluster, service, role):
           +        now = long(time.mktime(datetime.now().timetuple()))
           +        states[role] = {'status':'Started', 'start-time':now}
           +        Alert.send(cluster, service, role, now, True)
           +
           +
           +class MySQLConnector():
           +    @staticmethod
           +    def read(database, table):
           +        try:
           +            db = MySQLdb.connect(unix_socket=mysql_socket, db=database)
           +            cur = db.cursor()            
           +            query = "SELECT * FROM {0}".format(table)
           +            cur.execute(query)    
           +            return json.dumps(cur.fetchall())
           +        except Exception as err:
           +            logger.error("Could not access {0} table from {1}: {2}".format(table, database, err))
           +            return json.dumps(["Error", "Error: Could not access {0} table from {1}.".format(table, database)])     
           +            
           +    @staticmethod
           +    def read_ndbinfo(table):
           +        return MySQLConnector.read("ndbinfo", table)
           +    
           +    
           +class CommandHandler():
           +
           +    def response(self, code, msg):
           +        resp = HTTPResponse(status=code, output=msg)
           +        logger.info("{0}".format(resp))
           +        return resp
           +         
           +    def init(self, cluster, service, role):
           +        section = Config().section_name(cluster, service, role)
           +        if not services.has_section(section):
           +            return CommandHandler().response(400, 'Role not installed.')
           +        else:
           +            if Service().init(cluster, service, role) == True:
           +                return CommandHandler().response(200, 'Role initialized.')
           +            else:
           +                return CommandHandler().response(400, 'Error: Cannot initialize the service.')
           +    
           +    def start(self, cluster, service, role):
           +        section = Config().section_name(cluster, service, role)
           +        if not services.has_section(section):
           +            return CommandHandler().response(400, 'Role not installed.')
           +        elif states[role]['status'] == 'Started':
           +            return CommandHandler().response(400, 'Role already started.')
           +        else:
           +            res = Service().start(cluster, service, role)
           +            if res == False:
           +                return CommandHandler().response(400, 'Error: Cannot start the service.')
           +            else:
           +                return CommandHandler().response(200, "Role started.")
           +
           +    def stop(self, cluster, service, role):
           +        section = Config().section_name(cluster, service, role)
           +        if not services.has_section(section):
           +            return CommandHandler().response(400, 'Role not installed.')
           +        elif not states[role]['status'] == 'Started':
           +            return CommandHandler().response(400, 'Role is not running.')
           +        else:
           +            if Service().stop(cluster, service, role) == True:
           +                return CommandHandler().response(200, 'Role stopped.')
           +            else:
           +                return CommandHandler().response(400, 'Error: Cannot stop the service.')
           +
           +    def restart(self, cluster, service, role):
           +        section = Config().section_name(cluster, service, role)
           +        if not services.has_section(section):
           +            return CommandHandler().response(400, 'Role not installed.')
           +        else:
           +            res = Service().restart(cluster, service, role)
           +            if res == False:
           +                return CommandHandler().response(400, 'Error: Cannot restart the service.')
           +            else:
           +                return CommandHandler().response(200, "Role started.")
           +
           +    def read_log(self, cluster, service, role, lines):
           +        try:
           +            lines = int(lines)
           +            if role == None:
           +                section = Config().section_name(cluster, service)
           +            else:
           +                section = Config().section_name(cluster, service, role)                
           +            log_file_name = Config().get(section, "stdout-file")
           +            log = Util().tail(log_file_name, lines)
           +            return CommandHandler().response(200, log)
           +        
           +        except Exception as err:
           +            logger.error(err)
           +            return CommandHandler().response(400, "Cannot read file.")
           +
           +    def read_agent_log(self, lines):
           +        try:
           +            lines = int(lines)
           +            log = Util().tail(LOG_FILE, lines)
           +            return CommandHandler().response(200, log)
           +        
           +        except Exception as err:
           +            logger.error(err)
           +            return CommandHandler().response(400, "Cannot read file.")
           +
           +    def read_config(self, cluster, service, role):
           +        try:
           +            section = Config().section_name(cluster, service, role)
           +            config_file_name = Config().get(section, "config-file")
           +            with open(config_file_name) as config_file:
           +                conf = "".join(str(x) for x in (list(config_file)))
           +            return CommandHandler().response(200, conf)
           +        
           +        except Exception as err:
           +            logger.error(err)
           +            return CommandHandler().response(400, "Cannot read file.")
           +
           +    def info(self, cluster, service, role):
           +        try:
           +            section = Config().section_name(cluster, service, role)
           +            resp = json.dumps(Config().get_section(section))
           +            return CommandHandler().response(200, resp)
           +        
           +        except Exception as err:
           +            logger.error(err)
           +            return CommandHandler().response(400, "Cannot read file.")
           +
           +    def read_ndbinfo(self, table):
           +        res = MySQLConnector.read_ndbinfo(table)
           +        return CommandHandler().response(200, res)
           +                
           +    def execute(self, cluster, service, role, command, params):
           +        try:
           +            if role == None:
           +                section = Config().section_name(cluster, service)
           +            else:    
           +                section = Config().section_name(cluster, service, role)
           +            script = Config().get(section, "command-script")
           +            logger.info("Script name executing is: {0}".format(script))
           +            env = Config().get(section, "command-env")
           +            command = env + " " + script + " " + params
           +            command = re.sub(r'([\"])', r'\\\1', command)
           +            as_user = Config().get(section, "command-user")
           +# TODO: could check if as_user == "root" or as_user == "sudo" here...
           +            if not as_user:
           +                logger.warn("No user supplied to execute command: {0}".format(command))
           +                raise Exception("Not allowed execute command as user: {0}".format(as_user))
           +            if as_user:
           +                command = "su - " + as_user + " -c \"" + command + "\""
           +# TODO: shell=True is insecure when using untrused input
           +# as an attacker can input "hdfs dfs -ls / ; rm -rf /"
           +            p = Popen(command , shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
           +            out, err = p.communicate()        
           +            return CommandHandler().response(200, out)
           +        
           +        except Exception as err:
           +            logger.error(err)
           +            return CommandHandler().response(400, "Could not execute.")                
           +                
           +    def refresh(self):
           +        Heartbeat.send(False);
           +        return CommandHandler().response(200, "OK")
           +
           +
           +class Authentication():
           +    def check(self):
           +        result = False
           +        try:
           +            username = request.params['username']  
           +            inPassword = request.params['password']  
           +            if (username, inPassword) == (user, password):
           +                return True
           +        except Exception:
           +            result = False
           +
           +        if result == False:
           +            logger.info("Authentication failed: Invalid username/password: {0}/{1}".format(username, password))
           +        return result
           +    
           +    def failed(self):
           +        return HTTPResponse(status=400, output="Invalid username/password")
           +
           +
           +class SSLCherryPy(ServerAdapter):  
           +    def run(self, handler):  
           +        from cherrypy import wsgiserver  
           +        server = wsgiserver.CherryPyWSGIServer((self.host, self.port), handler)  
           +        # Certificate file. If a valid path, SSL will be used. Set to None to disable SSL  
           +        server.ssl_certificate = CERT_FILE
           +        server.ssl_private_key = KEY_FILE
           +        try:  
           +            server.start()  
           +        finally:  
           +            server.stop()
           +
           +if __name__ == '__main__':
           +    
           +    if len(sys.argv) > 1:
           +        if (sys.argv[1] == "-v" or sys.argv[1] == "-verbose" or sys.argv[1] == "--verbose"):
           +            verbose=True
           +        else:
           +            print "usage: <prog> [-v|-verbose]"
           +            sys.exit()
           +
           +    agent_pid = str(os.getpid())
           +    file(agent_pidfile, 'w').write(agent_pid)
           +    logger.info("Hops Kagent PID: {0}".format(agent_pid))
           +    logger.setLevel(Util().logging_level(logging_level))
           +
           +    # Heartbeat, process watch (alerts) and REST API are available after the agent registers successfully 
           +#    thread.start_new_thread(Heartbeat, ()) 
           +    hb_thread = threading.Thread(target=Heartbeat, args=())
           +    hb_thread.setDaemon(True)
           +    hb_thread.start()
           +
           +    for s in services.sections():
           +        cluster = Config().get(s, "cluster")
           +        service = Config().get(s, "service")       
           +        if services.has_option(s, "role"):
           +            role = Config().get(s, "role")             
           +#            thread.start_new_thread(ExtProcess.watch, (cluster, service, role))
           +            my_thread = threading.Thread(target=ExtProcess.watch, args=(cluster, service, role))
           +            my_thread.setDaemon(True)
           +            my_thread.start()
           +        else:
           +            logger.info("Not watching {0}/{1}".format(cluster, service))        
           +                            
           +    server_names['sslcherrypy'] = SSLCherryPy  
           +    app = Bottle()
           +    @get('/ping')
           +    def ping():
           +        logger.info('Incoming REST Request:  GET /ping')       
           +        return "Hops-Agent: Pong"
           +        
           +    @get('/do/<cluster>/<service>/<role>/<command>')
           +    def do(cluster, service, role, command):
           +        logger.info('Incoming REST Request:  GET /do/{0}/{1}/{2}/{3}'.format(cluster, service, role, command))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        section = Config().section_name(cluster, service, role)
           +        logger.info("Section is {0}".format(section))
           +        if not services.has_section(section):
           +            logger.error("Couldn't find command {0} in {1}/{2} in section {3}".format(command, service, role, section))
           +            return HTTPResponse(status=400, output='Invalid command.')            
           +
           +        serviceInServicesFile = Config().get(section, "service")
           +        roleInServicesFile = Config().get(section, "role")
           +        commandInServicesFile = Config().get(section, "{0}-script".format(command))
           +
           +        if (not service == serviceInServicesFile) or (not role == roleInServicesFile) or (not commandInServicesFile):
           +            logger.error("Couldn't find command {0} in {1}/{2}".format(command, service, role))
           +            return HTTPResponse(status=400, output='Invalid command.')            
           +        
           +        if command == "start":
           +            return CommandHandler().start(cluster, service, role);
           +        elif command == "stop":
           +            return CommandHandler().stop(cluster, service, role);                
           +        elif command == "init":
           +            return CommandHandler().init(cluster, service, role); 
           +        else:
           +            return HTTPResponse(status=400, output='Invalid command.')        
           +
           +    @get('/restartRole/<cluster>/<service>/<role>')
           +    def restartRole(cluster, service, role):
           +        logger.info('Incoming REST Request:  GET /restartRole/{0}/{1}'.format(cluster, service, role))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +
           +        return CommandHandler().restart(cluster, service, role);
           +
           +    @get('/startRole/<cluster>/<service>/<role>')
           +    def startRole(cluster, service, role):
           +        logger.info('Incoming REST Request:  GET /startRole/{0}/{1}'.format(cluster, service, role))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +
           +        return CommandHandler().start(cluster, service, role);
           +
           +    @get('/stopRole/<cluster>/<service>/<role>')
           +    def stopRole(cluster, service, role):
           +        logger.info('Incoming REST Request:  GET /stopRole/{0}/{1}/{2}'.format(cluster, service, role))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +
           +        return CommandHandler().stop(cluster, service, role);
           +
           +    @get('/log/<cluster>/<service>/<role>/<lines>')
           +    def log(cluster, service, role, lines):
           +        logger.info('Incoming REST Request:  GET /log/{0}/{1}/{2}'.format(cluster, service, role, lines))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +
           +        return CommandHandler().read_log(cluster, service, role, lines);
           +
           +
           +    @get('/log/<cluster>/<service>/<lines>')
           +    def log(cluster, service, lines):
           +        logger.info('Incoming REST Request:  GET /log/{0}/{1}'.format(cluster, service))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service)):
           +            return HTTPResponse(status=400, output='Cluster/Service not available.')
           +
           +        return CommandHandler().read_log(cluster, service, None, lines);
           +
           +
           +    @get('/agentlog/<lines>')
           +    def agentlog(lines):
           +        logger.info('Incoming REST Request:  GET /agentlog/{0}'.format(lines))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +                                    
           +        return CommandHandler().read_agent_log(lines);
           +
           +    @get('/config/<cluster>/<service>/<role>')
           +    def config(cluster, service, role):
           +        logger.info('Incoming REST Request:  GET /log/{0}/{1}/{2}'.format(cluster, service, role))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +            
           +        return CommandHandler().read_config(cluster, service, role);
           +
           +    @get('/info/<cluster>/<service>/<role>')
           +    def info(cluster, service, role):
           +        logger.info('Incoming REST Request:  GET /status/{0}/{1}'.format(cluster, service, role))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +        
           +        if not services.has_section(Config().section_name(cluster, service, role)):
           +            return HTTPResponse(status=400, output='Cluster/Service/Role not available.')
           +            
           +        return CommandHandler().info(cluster, service, role);
           +
           +    @get('/refresh')  # request heartbeat
           +    def refresh():
           +        logger.info('Incoming REST Request:  GET /refresh')
           +        if not Authentication().check():
           +            return Authentication().failed()
           +             
           +        return CommandHandler().refresh();
           +
           +    @get('/mysql/ndbinfo/<table>')
           +    def mysql_read(table):
           +        logger.info('Incoming REST Request:  GET /mysql/ndbinfo/{0}'.format(table))
           +        if not Authentication().check():
           +            return Authentication().failed()
           +            
           +        return CommandHandler().read_ndbinfo(table)
           +    
           +    @post('/execute/<state>/<cluster>/<service>/<role>/<command>')
           +    def execute_hdfs(state, cluster, service, role, command):
           +        logger.info('Incoming REST Request:  POST /execute/{0}/{1}/{2}/{3}/{4}'.format(state, cluster, service, role, command))
           +        if not Authentication().check():
           +            return Authentication().failed()            
           +        if request.body.readlines():
           +            params =  request.body.readlines()[0]
           +        else:
           +            params = ""                        
           +        if state == "run" :
           +            if role == "-":
           +                return CommandHandler().execute(cluster, service, None, command, params);
           +            else:       
           +                return CommandHandler().execute(cluster, service, role, command, params);
           +        return CommandHandler().response(404, "Error")  
           +                
           +
           +    logger.info("RESTful service started.")
           +    run(host='0.0.0.0', port=agent_restport, server='sslcherrypy')
           +
           +
           - change mode from '' to '0710'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent-certs/csr.py] action create
           - create new file /var/lib/kagent-certs/csr.py
           - update content in file /var/lib/kagent-certs/csr.py from none to e68d39
           --- /var/lib/kagent-certs/csr.py	2016-08-26 14:16:03.362072741 +0000
           +++ /var/lib/kagent-certs/.chef-csr.py20160826-1220-bjqdys	2016-08-26 14:16:03.362072741 +0000
           @@ -1 +1,262 @@
           +#!/usr/bin/env python
           +
           +'''
           +@author: Jim Dowling <jdowling@kth.se>
           +
           +Install:
           + requests:    easy_install requests
           + Netifaces:   easy_install netifaces
           + IPy:         easy_install ipy
           + pyOpenSSL:   apt-get install python-openssl
           + MySQLdb:     apt-get install python-mysqldb
           + pexpect:     apt-get install python-pexpect
           +'''
           +
           +import time
           +from threading import Lock
           +import os
           +import sys
           +import ConfigParser
           +import requests
           +import logging.handlers
           +import json
           +from OpenSSL import crypto
           +import socket
           +from os.path import exists, join
           +import netifaces
           +from IPy import IP
           +import logging
           +import subprocess
           +import string
           +import random
           +
           +
           +try:
           +    import http.client as http_client
           +except ImportError:
           +    # Python 2
           +    import httplib as http_client
           +http_client.HTTPConnection.debuglevel = 1
           +
           +logging.basicConfig()
           +logging.getLogger().setLevel(logging.DEBUG)
           +requests_log = logging.getLogger("requests.packages.urllib3")
           +requests_log.setLevel(logging.DEBUG)
           +requests_log.propagate = True
           +retries = 20
           +
           +class Util():
           +
           +    def logging_level(self, level):
           +        return {
           +                'INFO': logging.INFO,
           +                'WARN': logging.WARN,
           +                'WARNING': logging.WARNING,
           +                'ERROR': logging.ERROR,
           +                'DEBUG' : logging.DEBUG,
           +                'CRITICAL': logging.CRITICAL,
           +                }.get(level, logging.NOTSET)
           +
           +
           +class Register():
           +
           +    def __init__(self, csr, key):
           +        while True:
           +            cert = Register.register(csr, key)
           +            if cert != None:
           +                Cert.store(cert, key)
           +                break
           +            time.sleep(heartbeat_interval)
           +
           +    @staticmethod
           +    def register(csr, key):
           +            try:
           +		json_headers = {'User-Agent': 'Agent', 'content-type': 'application/json'}
           +        	form_headers = {'User-Agent': 'Agent', 'content-type': 'application/x-www-form-urlencoded'}
           +		payload = {}
           +                payload["csr"] = csr
           +                payload["agent-password"] = agent_password
           +                payload["host-id"] = host_id            
           +                logger.info("Registering with HopsWorks...")
           +		session = requests.Session()
           +		session.post(login_url, data={'email': server_username, 'password': server_password}, headers=form_headers, verify=False)
           +		resp = session.post(register_url, data=json.dumps(payload), headers=json_headers, verify=False)
           +		if not resp.status_code == HTTP_OK:
           +               		raise Exception('Could not register: Unknown host id or internal error on the dashboard (Status code: {0}).'.format(resp.status_code))
           +                
           +                # Loads (Load String) takes a Json file and converts into python data structure (dict or list, depending on JSON)
           +                # jData = json.loads(myResponse.content)
           +                jData = json.loads(resp.content)
           +                cert = jData['pubAgentCert']
           +                caCert = jData['caPubCert']
           +
           +                cert_dir = os.path.dirname(os.path.abspath(__file__))
           +                with open(join(cert_dir, CA_FILE), "wt") as f:
           +                    f.write(caCert)
           +                logger.info("Writing Ca Public key to {0}.".format(CA_FILE))
           +
           +                logger.info("Registered successfully.")
           +                return cert
           +            except Exception as err:
           +                logger.error("{0}. Retrying in {1} seconds...".format(err, heartbeat_interval))
           +                return None
           +
           +class Cert():
           +
           +    @staticmethod
           +    def get_dir():
           +        return os.path.dirname(os.path.abspath(__file__))
           +
           +    @staticmethod
           +    def exist():
           +        cert_dir = Cert.get_dir()
           +        return exists(join(cert_dir, CERT_FILE)) and exists(join(cert_dir, KEY_FILE))
           +
           +    @staticmethod
           +    def existsKeystore():
           +        return exists(SERVER_KEYSTORE) and exists(SERVER_TRUSTSTORE) and exists(CLIENT_TRUSTSTORE)
           +    
           +    @staticmethod
           +    def create_key_and_csr():
           +        """
           +        Create key-pair and certificate sign request (CSR)
           +        """
           +        # create a key pair
           +        pkey = crypto.PKey()
           +        pkey.generate_key(crypto.TYPE_RSA, 2048)
           +        # create certificate sign request
           +        req = crypto.X509Req()
           +        req.get_subject().C = "SE"
           +        req.get_subject().ST = "Sweden"
           +        req.get_subject().L = "Stockholm"
           +        req.get_subject().O = "HopsWorks"
           +        req.get_subject().OU = "KTH"
           +        req.get_subject().CN = hostname
           +        req.set_pubkey(pkey)
           +        req.sign(pkey, 'sha256')
           +        csr = crypto.dump_certificate_request(crypto.FILETYPE_PEM, req)
           +        private_key = crypto.dump_privatekey(crypto.FILETYPE_PEM, pkey)
           +        return csr, private_key
           +
           +    @staticmethod
           +    def store(cert, key):
           +        """
           +        Write certificate and private key in current directory
           +        """
           +        cert_dir = Cert.get_dir()
           +        with open(join(cert_dir, CERT_FILE), "wt") as f:
           +            f.write(cert)
           +        with open(join(cert_dir, KEY_FILE), "wt") as f:
           +            f.write(key)
           +        logger.info("Writing Cert/Key pair to {0} - {1}.".format(CERT_FILE, KEY_FILE))
           +
           +var="~#@#@!#@!#!@#@!#"
           +
           +config_mutex = Lock()
           +
           +HTTP_OK = 200
           +
           +CONFIG_FILE = "/var/lib/kagent/config.ini"
           +LOG_FILE = "/var/lib/kagent/csr.log"
           +CERT_FILE = "/var/lib/kagent-certs/pub.pem"
           +CA_FILE = "/var/lib/kagent-certs/ca_pub.pem"
           +KEY_FILE = "/var/lib/kagent-certs/priv.key"
           +SERVER_KEYSTORE = "/var/lib/kagent-certs/keystores/node_server_keystore.jks"
           +SERVER_TRUSTSTORE = "/var/lib/kagent-certs/keystores/node_server_truststore.jks"
           +CLIENT_TRUSTSTORE = "/var/lib/kagent-certs/keystores/node_client_truststore.jks"
           +
           +# reading config
           +try:
           +    config = ConfigParser.ConfigParser()
           +    config.read(CONFIG_FILE)
           +    server_url = config.get('server', 'url')
           +    register_url = server_url + config.get('server', 'path-register')
           +    login_url = server_url + config.get('server', 'path-login')
           +    server_username = config.get('server', 'username')
           +    server_password = config.get('server', 'password')
           +
           +    heartbeat_interval = config.getfloat('agent', 'heartbeat-interval')
           +    logging_level = config.get('agent', 'logging-level').upper()
           +    max_log_size = config.getint('agent', 'max-log-size')
           +    agent_pidfile = config.get('agent', 'pid-file')
           +    network_interface = config.get('agent', 'network-interface')
           +
           +    if (config.has_option("agent", "hostname")):
           +        hostname = config.get("agent", "hostname")
           +    else:
           +        hostname = socket.gethostbyaddr(eth0_ip)[0]
           +        
           +    if (config.has_option("agent", "host-id")):
           +        host_id = config.get("agent", "host-id")
           +    else:
           +        host_id = hostname
           +
           +
           +    agent_password = ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(8))    
           +    config.set('agent', 'password', agent_password)
           +    with open(CONFIG_FILE, 'wb') as configfile: 
           +        config.write(configfile)
           +
           +# TODO find public/private IP addresses
           +    public_ip = None
           +    private_ip = None
           +    eth0_ip = netifaces.ifaddresses(network_interface)[netifaces.AF_INET][0]['addr']
           +    if (IP(eth0_ip).iptype() == "PUBLIC"):
           +        public_ip = eth0_ip
           +    else:
           +        private_ip = eth0_ip
           +
           +    hostname = socket.gethostbyaddr(eth0_ip)[0]
           +
           +    if (config.has_option("agent", "host-id")):
           +        host_id = config.get("agent", "host-id")
           +    else:
           +        host_id = hostname
           +
           +
           +except Exception, e:
           +    print "Exception while reading {0}: {1}".format(CONFIG_FILE, e)
           +    sys.exit(1)
           +
           +# logging
           +try:
           +    os.remove(LOG_FILE + '.1')
           +except:
           +    pass
           +with open(LOG_FILE, 'w'):  # clear log file
           +    pass
           +logger = logging.getLogger('agent')
           +logger_formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
           +logger_file_handler = logging.handlers.RotatingFileHandler(LOG_FILE, "w", maxBytes=max_log_size, backupCount=1)
           +logger_stream_handler = logging.StreamHandler()
           +logger_file_handler.setFormatter(logger_formatter)
           +logger_stream_handler.setFormatter(logger_formatter)
           +logger.addHandler(logger_file_handler)
           +logger.addHandler(logger_stream_handler)
           +logger.setLevel(logging.INFO)
           +
           +logger.info("Hops Csr-Agent started.")
           +logger.info("Register URL: {0}".format(register_url))
           +logger.info("Public IP: {0}".format(public_ip))
           +logger.info("Private IP: {0}".format(private_ip))
           +
           +
           +if __name__ == '__main__':
           +
           +    agent_pid = str(os.getpid())
           +    file(agent_pidfile, 'w').write(agent_pid)
           +    logger.info("Hops-CSR-Agent PID: {0}".format(agent_pid))
           +    logger.setLevel(Util().logging_level(logging_level))
           +
           +    if not Cert.exist():
           +        (csr, key) = Cert.create_key_and_csr()
           +        Register(csr, key) # Registering with the dashboard
           +        subprocess.call("/var/lib/kagent/keystore.sh")
           +    else:
           +        logger.info('Certificate files exist. Already registered. Skipping registration phase.')
           +
           +    if not Cert.existsKeystore():
           +        subprocess.call("/var/lib/kagent/keystore.sh")
           +    else:
           +        logger.info('Keystore files found.')
           - change mode from '' to '0710'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/start-agent.sh] action create
           - create new file /var/lib/kagent/bin/start-agent.sh
           - update content in file /var/lib/kagent/bin/start-agent.sh from none to dd1d26
           --- /var/lib/kagent/bin/start-agent.sh	2016-08-26 14:16:03.390058742 +0000
           +++ /var/lib/kagent/bin/.chef-start-agent.sh20160826-1220-ixevi1	2016-08-26 14:16:03.390058742 +0000
           @@ -1 +1,23 @@
           +#!/bin/bash
           +# returns '0' if agent started successfully
           +# returns '1' if agent already running
           +
           +source /var/lib/kagent/bin/get-pid.sh
           +
           +if [ $? -ne 0 ]; then
           +	echo "Starting the agent..."
           +	nohup /var/lib/kagent/agent.py &> /dev/null &
           +        sleep 1
           +        PID_FILE=/var/lib/kagent/kagent.pid
           +        if [ -e $PID_FILE ] ; then
           +          PID=`cat $PID_FILE`
           +          echo "PID is $PID"
           +        fi
           +else
           +    echo "Agent is already running with pid=$PID."
           +    exit 1
           +fi
           +echo ""
           +exit 0
           +
           - change mode from '' to '0750'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/stop-agent.sh] action create
           - create new file /var/lib/kagent/bin/stop-agent.sh
           - update content in file /var/lib/kagent/bin/stop-agent.sh from none to f441d2
           --- /var/lib/kagent/bin/stop-agent.sh	2016-08-26 14:16:03.398054743 +0000
           +++ /var/lib/kagent/bin/.chef-stop-agent.sh20160826-1220-1occoim	2016-08-26 14:16:03.398054743 +0000
           @@ -1 +1,12 @@
           +#!/bin/bash
           +
           +source /var/lib/kagent/bin/get-pid.sh
           +
           +if [ $? -ne 0 ]; then
           +	echo "Agent is not running."
           +else
           +	echo "Agent's process-id is $PID. Killing the agent..."
           +	kill -9 $PID
           +fi
           +exit $?
           - change mode from '' to '0750'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/restart-agent.sh] action create
           - create new file /var/lib/kagent/bin/restart-agent.sh
           - update content in file /var/lib/kagent/bin/restart-agent.sh from none to fad0db
           --- /var/lib/kagent/bin/restart-agent.sh	2016-08-26 14:16:03.406050742 +0000
           +++ /var/lib/kagent/bin/.chef-restart-agent.sh20160826-1220-1gqh73x	2016-08-26 14:16:03.406050742 +0000
           @@ -1 +1,7 @@
           +#!/bin/bash
           +
           +/var/lib/kagent/bin/stop-agent.sh
           +sleep 3
           +/var/lib/kagent/bin/start-agent.sh
           +exit $?
           - change mode from '' to '0750'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/get-pid.sh] action create
           - create new file /var/lib/kagent/bin/get-pid.sh
           - update content in file /var/lib/kagent/bin/get-pid.sh from none to a52e33
           --- /var/lib/kagent/bin/get-pid.sh	2016-08-26 14:16:03.414046743 +0000
           +++ /var/lib/kagent/bin/.chef-get-pid.sh20160826-1220-1ik7z1z	2016-08-26 14:16:03.414046743 +0000
           @@ -1 +1,12 @@
           +echo ""
           +echo "Checking if the agent is running...."
           +echo ""
           +PID_FILE=/var/lib/kagent/kagent.pid
           +PID=""
           +if [ -e $PID_FILE ] ; then
           +  PID=`cat $PID_FILE`
           +fi
           +echo "PID is $PID"
           +echo ""
           +kill -0 $PID 2> /dev/null
           - change mode from '' to '0750'
           - change owner from '' to 'kagent'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/services] action create
           - change mode from '0755' to '0644'
         * template[/var/lib/kagent/bin/start-service.sh] action create
           - create new file /var/lib/kagent/bin/start-service.sh
           - update content in file /var/lib/kagent/bin/start-service.sh from none to aee170
           --- /var/lib/kagent/bin/start-service.sh	2016-08-26 14:16:03.426040743 +0000
           +++ /var/lib/kagent/bin/.chef-start-service.sh20160826-1220-1683ryk	2016-08-26 14:16:03.426040743 +0000
           @@ -1 +1,11 @@
           +#!/bin/bash
           +
           +set -e
           +
           +if [ $# -ne 1 ] ; then
           +  echo "Usage: $0 service_name"
           +  exit 2
           +fi
           +
           +sudo service $1 start
           - change mode from '' to '0750'
           - change owner from '' to 'root'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/stop-service.sh] action create
           - create new file /var/lib/kagent/bin/stop-service.sh
           - update content in file /var/lib/kagent/bin/stop-service.sh from none to 34798e
           --- /var/lib/kagent/bin/stop-service.sh	2016-08-26 14:16:03.434036743 +0000
           +++ /var/lib/kagent/bin/.chef-stop-service.sh20160826-1220-1qg6b7x	2016-08-26 14:16:03.434036743 +0000
           @@ -1 +1,11 @@
           +#!/bin/bash
           +
           +set -e
           +
           +if [ $# -ne 1 ] ; then
           +  echo "Usage: $0 service_name"
           +  exit 2
           +fi
           +
           +sudo service $1 stop
           - change mode from '' to '0750'
           - change owner from '' to 'root'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/restart-service.sh] action create
           - create new file /var/lib/kagent/bin/restart-service.sh
           - update content in file /var/lib/kagent/bin/restart-service.sh from none to 416b5b
           --- /var/lib/kagent/bin/restart-service.sh	2016-08-26 14:16:03.438034744 +0000
           +++ /var/lib/kagent/bin/.chef-restart-service.sh20160826-1220-1rgh1zp	2016-08-26 14:16:03.438034744 +0000
           @@ -1 +1,11 @@
           +#!/bin/bash
           +
           +set -e
           +
           +if [ $# -ne 1 ] ; then
           +  echo "Usage: $0 service_name"
           +  exit 2
           +fi
           +
           +sudo service $1 restart
           - change mode from '' to '0750'
           - change owner from '' to 'root'
           - change group from '' to 'kagent'
         * template[/var/lib/kagent/bin/status-service.sh] action create
           - create new file /var/lib/kagent/bin/status-service.sh
           - update content in file /var/lib/kagent/bin/status-service.sh from none to b0f789
           --- /var/lib/kagent/bin/status-service.sh	2016-08-26 14:16:03.446030743 +0000
           +++ /var/lib/kagent/bin/.chef-status-service.sh20160826-1220-ldbkvj	2016-08-26 14:16:03.446030743 +0000
           @@ -1 +1,11 @@
           +#!/bin/bash
           +
           +set -e
           +
           +if [ $# -ne 1 ] ; then
           +  echo "Usage: $0 service_name"
           +  exit 2
           +fi
           +
           +sudo service $1 status
           - change mode from '' to '0750'
           - change owner from '' to 'root'
           - change group from '' to 'kagent'
         * template[/etc/sudoers.d/kagent] action create
           - create new file /etc/sudoers.d/kagent
           - update content in file /etc/sudoers.d/kagent from none to b295b0
           --- /etc/sudoers.d/kagent	2016-08-26 14:16:03.454026744 +0000
           +++ /etc/sudoers.d/.chef-kagent20160826-1220-1kwpmlb	2016-08-26 14:16:03.454026744 +0000
           @@ -1 +1,8 @@
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/start-service.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/stop-service.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/restart-service.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/status-service.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/start-all-local-services.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/shutdown-all-local-services.sh
           +kagent ALL=NOPASSWD: /var/lib/kagent/bin/status-all-local-services.sh
           - change mode from '' to '0440'
           - change owner from '' to 'root'
           - change group from '' to 'root'
       Recipe: sysctl::service
         * template[/etc/rc.d/init.d/procps] action create (skipped due to only_if)
         * service[procps] action enable (up to date)
       Recipe: sysctl::default
         * directory[/etc/sysctl.d] action create (up to date)
         * ruby_block[save-sysctl-params] action nothing (skipped due to action :nothing)
         * ruby_block[apply-sysctl-params] action nothing (skipped due to action :nothing)
         * template[/etc/sysctl.d/99-chef-attributes.conf] action nothing (skipped due to action :nothing)
       Recipe: sysctl::apply
         * ruby_block[notify-apply-sysctl-params] action run
           - execute the ruby block notify-apply-sysctl-params
       Recipe: sysctl::default
         * ruby_block[apply-sysctl-params] action run
           - execute the ruby block apply-sysctl-params
         * template[/etc/sysctl.d/99-chef-attributes.conf] action create
           - create new file /etc/sysctl.d/99-chef-attributes.conf
           - update content in file /etc/sysctl.d/99-chef-attributes.conf from none to 163611
           --- /etc/sysctl.d/99-chef-attributes.conf	2016-08-26 14:16:03.474016744 +0000
           +++ /etc/sysctl.d/.chef-99-chef-attributes.conf20160826-1220-uql8g4	2016-08-26 14:16:03.474016744 +0000
           @@ -1 +1,8 @@
           +# Dynamically generated file dropped off by Chef!
           +
           +net.core.somaxconn=1024
           +vm.overcommit_memory=1
           +vm.overcommit_ratio=100
           +vm.swappiness=1
           +
           - change mode from '' to '0644'
       Recipe: sysctl::service
         * service[procps] action restart
           - restart service service[procps]
       Recipe: apache_hadoop::install
         * bash[configure_os] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1dtz90d"
       Recipe: java::notify
         * log[jdk-version-changed] action nothing (skipped due to action :nothing)
       Recipe: java::set_java_home
         * ruby_block[set-env-java-home] action run
           - execute the ruby block set-env-java-home
         * directory[/etc/profile.d] action create (up to date)
         * template[/etc/profile.d/jdk.sh] action create
           - create new file /etc/profile.d/jdk.sh
           - update content in file /etc/profile.d/jdk.sh from none to 973b46
           --- /etc/profile.d/jdk.sh	2016-08-26 14:16:03.565970747 +0000
           +++ /etc/profile.d/.chef-jdk.sh20160826-1220-18gc2be	2016-08-26 14:16:03.565970747 +0000
           @@ -1 +1,2 @@
           +export JAVA_HOME=/usr/lib/jvm/java-8-oracle-amd64
           - change mode from '' to '0755'
         * ruby_block[Set JAVA_HOME in /etc/environment] action run
           - execute the ruby block Set JAVA_HOME in /etc/environment
       Recipe: java::oracle
         * apt_package[tar] action install (up to date)
         * java_ark[jdk] action install
           - create dir /usr/lib/jvm and change owner to root:root
           * apt_package[curl] action install
             - install version 7.35.0-1ubuntu2.8 of package curl
           - download oracle tarball straight from the server
           - extract compressed data into Chef file cache path and
                        move extracted data to /usr/lib/jvm/jdk1.8.0_101
           - Add /usr/lib/jvm/.java-8-oracle-amd64.jinfo for debian
           - Symlink /usr/lib/jvm/jdk1.8.0_101 to /usr/lib/jvm/java-8-oracle-amd64
       Recipe: java::notify
         * log[jdk-version-changed] action write
         
         * apt_package[curl] action nothing (skipped due to action :nothing)
         * template[/usr/lib/jvm/.java-8-oracle-amd64.jinfo] action create
           - create new file /usr/lib/jvm/.java-8-oracle-amd64.jinfo
           - update content in file /usr/lib/jvm/.java-8-oracle-amd64.jinfo from none to ea344c
           --- /usr/lib/jvm/.java-8-oracle-amd64.jinfo	2016-08-26 14:16:20.977261207 +0000
           +++ /usr/lib/jvm/.chef-.java-8-oracle-amd64.jinfo20160826-1220-1abyvrt	2016-08-26 14:16:20.977261207 +0000
           @@ -1 +1,52 @@
           +name=java-8-oracle-amd64
           +priority=1062
           +section=main
           +
           +jdk appletviewer /usr/lib/jvm/java-8-oracle-amd64/bin/appletviewer
           +jdk apt /usr/lib/jvm/java-8-oracle-amd64/bin/apt
           +jdk ControlPanel /usr/lib/jvm/java-8-oracle-amd64/bin/ControlPanel
           +jdk extcheck /usr/lib/jvm/java-8-oracle-amd64/bin/extcheck
           +jdk idlj /usr/lib/jvm/java-8-oracle-amd64/bin/idlj
           +jdk jar /usr/lib/jvm/java-8-oracle-amd64/bin/jar
           +jdk jarsigner /usr/lib/jvm/java-8-oracle-amd64/bin/jarsigner
           +jdk java /usr/lib/jvm/java-8-oracle-amd64/bin/java
           +jdk javac /usr/lib/jvm/java-8-oracle-amd64/bin/javac
           +jdk javadoc /usr/lib/jvm/java-8-oracle-amd64/bin/javadoc
           +jdk javafxpackager /usr/lib/jvm/java-8-oracle-amd64/bin/javafxpackager
           +jdk javah /usr/lib/jvm/java-8-oracle-amd64/bin/javah
           +jdk javap /usr/lib/jvm/java-8-oracle-amd64/bin/javap
           +jdk javaws /usr/lib/jvm/java-8-oracle-amd64/bin/javaws
           +jdk jcmd /usr/lib/jvm/java-8-oracle-amd64/bin/jcmd
           +jdk jconsole /usr/lib/jvm/java-8-oracle-amd64/bin/jconsole
           +jdk jcontrol /usr/lib/jvm/java-8-oracle-amd64/bin/jcontrol
           +jdk jdb /usr/lib/jvm/java-8-oracle-amd64/bin/jdb
           +jdk jdeps /usr/lib/jvm/java-8-oracle-amd64/bin/jdeps
           +jdk jhat /usr/lib/jvm/java-8-oracle-amd64/bin/jhat
           +jdk jinfo /usr/lib/jvm/java-8-oracle-amd64/bin/jinfo
           +jdk jjs /usr/lib/jvm/java-8-oracle-amd64/bin/jjs
           +jdk jmap /usr/lib/jvm/java-8-oracle-amd64/bin/jmap
           +jdk jmc /usr/lib/jvm/java-8-oracle-amd64/bin/jmc
           +jdk jps /usr/lib/jvm/java-8-oracle-amd64/bin/jps
           +jdk jrunscript /usr/lib/jvm/java-8-oracle-amd64/bin/jrunscript
           +jdk jsadebugd /usr/lib/jvm/java-8-oracle-amd64/bin/jsadebugd
           +jdk jstack /usr/lib/jvm/java-8-oracle-amd64/bin/jstack
           +jdk jstat /usr/lib/jvm/java-8-oracle-amd64/bin/jstat
           +jdk jstatd /usr/lib/jvm/java-8-oracle-amd64/bin/jstatd
           +jdk jvisualvm /usr/lib/jvm/java-8-oracle-amd64/bin/jvisualvm
           +jdk keytool /usr/lib/jvm/java-8-oracle-amd64/bin/keytool
           +jdk native2ascii /usr/lib/jvm/java-8-oracle-amd64/bin/native2ascii
           +jdk orbd /usr/lib/jvm/java-8-oracle-amd64/bin/orbd
           +jdk pack200 /usr/lib/jvm/java-8-oracle-amd64/bin/pack200
           +jdk policytool /usr/lib/jvm/java-8-oracle-amd64/bin/policytool
           +jdk rmic /usr/lib/jvm/java-8-oracle-amd64/bin/rmic
           +jdk rmid /usr/lib/jvm/java-8-oracle-amd64/bin/rmid
           +jdk rmiregistry /usr/lib/jvm/java-8-oracle-amd64/bin/rmiregistry
           +jdk schemagen /usr/lib/jvm/java-8-oracle-amd64/bin/schemagen
           +jdk serialver /usr/lib/jvm/java-8-oracle-amd64/bin/serialver
           +jdk servertool /usr/lib/jvm/java-8-oracle-amd64/bin/servertool
           +jdk tnameserv /usr/lib/jvm/java-8-oracle-amd64/bin/tnameserv
           +jdk unpack200 /usr/lib/jvm/java-8-oracle-amd64/bin/unpack200
           +jdk wsgen /usr/lib/jvm/java-8-oracle-amd64/bin/wsgen
           +jdk wsimport /usr/lib/jvm/java-8-oracle-amd64/bin/wsimport
           +jdk xjc /usr/lib/jvm/java-8-oracle-amd64/bin/xjc
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * java_alternatives[set-java-alternatives] action set
           - Add alternative for appletviewer
           - Add alternative for ControlPanel
           - Add alternative for extcheck
           - Add alternative for idlj
           - Add alternative for jar
           - Add alternative for jarsigner
           - Add alternative for java
           - Add alternative for javac
           - Add alternative for javadoc
           - Add alternative for javafxpackager
           - Add alternative for javah
           - Add alternative for javap
           - Add alternative for javaws
           - Add alternative for jcmd
           - Add alternative for jconsole
           - Add alternative for jcontrol
           - Add alternative for jdb
           - Add alternative for jdeps
           - Add alternative for jhat
           - Add alternative for jinfo
           - Add alternative for jjs
           - Add alternative for jmap
           - Add alternative for jmc
           - Add alternative for jps
           - Add alternative for jrunscript
           - Add alternative for jsadebugd
           - Add alternative for jstack
           - Add alternative for jstat
           - Add alternative for jstatd
           - Add alternative for jvisualvm
           - Add alternative for keytool
           - Add alternative for native2ascii
           - Add alternative for orbd
           - Add alternative for pack200
           - Add alternative for policytool
           - Add alternative for rmic
           - Add alternative for rmid
           - Add alternative for rmiregistry
           - Add alternative for schemagen
           - Add alternative for serialver
           - Add alternative for servertool
           - Add alternative for tnameserv
           - Add alternative for unpack200
           - Add alternative for wsgen
           - Add alternative for wsimport
           - Add alternative for xjc
       Recipe: java::default_java_symlink
         * link[/usr/lib/jvm/default-java] action create
           - create symlink at /usr/lib/jvm/default-java to /usr/lib/jvm/java-8-oracle-amd64
       Recipe: apache_hadoop::install
         * group[hadoop] action create
           - create group hadoop
         * user[hdfs] action create
           - create user hdfs
         * user[yarn] action create
           - create user yarn
         * user[mapred] action create
           - create user mapred
         * group[hadoop] action modify
           - modify group hadoop
           - add missing member(s): hdfs, yarn, mapred
         * apt_package[openssh-server] action install (up to date)
         * apt_package[openssh-client] action install (up to date)
         * directory[/srv] action create (skipped due to not_if)
         * directory[/var/data/hadoop] action create
           - create new directory /var/data/hadoop
           - change mode from '' to '0774'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * directory[/var/data/hadoop/hdfs/dn] action create
           - create new directory /var/data/hadoop/hdfs/dn
           - change mode from '' to '0774'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * directory[/var/data/hadoop/hdfs/nn] action create
           - create new directory /var/data/hadoop/hdfs/nn
           - change mode from '' to '0774'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * remote_file[/tmp/hadoop-2.4.0.tar.gz] action create_if_missing
           - create new file /tmp/hadoop-2.4.0.tar.gz
           - update content in file /tmp/hadoop-2.4.0.tar.gz from none to 9eeb0e
           (file sizes exceed 10000000 bytes, diff output suppressed)
           - change mode from '' to '0755'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * remote_file[/tmp/hadoop-2.4.0.tar.gz] action create_if_missing (skipped due to not_if)
         * bash[extract-hadoop] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-11p5hf"
         * directory[/srv/hadoop-2.4.0/logs] action create
           - create new directory /srv/hadoop-2.4.0/logs
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * directory[/srv/hadoop-2.4.0/tmp] action create
           - create new directory /srv/hadoop-2.4.0/tmp
           - change mode from '' to '01777'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * link[/srv/hadoop] action create
           - unlink existing symlink to file at /srv/hadoop
           - create symlink at /srv/hadoop to /srv/hadoop-2.4.0
       Recipe: apache_hadoop::default
         * template[/srv/hadoop-2.4.0/etc/hadoop/core-site.xml] action create_if_missing
           - create new file /srv/hadoop-2.4.0/etc/hadoop/core-site.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/core-site.xml from none to f1a35f
           --- /srv/hadoop-2.4.0/etc/hadoop/core-site.xml	2016-08-26 14:16:43.669909807 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-core-site.xml20160826-1220-1vqmavi	2016-08-26 14:16:43.665911806 +0000
           @@ -1 +1,53 @@
           +<?xml version="1.0"?>
           +<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
           +
           +<!-- Put site-specific property overrides in this file. -->
           +
           +<configuration>
           +
           +<!-- In: conf/core-site.xml -->
           +<property>
           +  <name>hadoop.tmp.dir</name>
           +  <value>/srv/hadoop-2.4.0/tmp</value>
           +  <description>A base for other temporary directories.</description>
           +</property>
           +
           +<property>
           +  <name>io.file.buffer.size</name>
           +  <value>131072</value>
           +  <description>Size of read/write buffer used in SequenceFiles.</description>
           +</property>
           +
           +<property>
           +  <name>ipc.client.connect.max.retries</name>
           +  <value>0</value>
           +  <description></description>
           +</property>
           +
           +
           + <property>
           +  <name>fs.defaultFS</name>
           +  <value>hdfs://10.0.2.15:8020</value>
           + </property>
           +
           +<!-- Hops-Hub WebHDFS proxy user setting -->
           +<!-- See http://www.cloudera.com/content/cloudera/en/documentation/cdh4/v4-2-0/CDH4-Installation-Guide/cdh4ig_topic_15_4.html -->
           +<!--
           +<property>
           +  <name>hadoop.proxyuser.hopshub.hosts</name>
           +  <value>*</value>
           +</property>
           +<property>
           +  <name>hadoop.proxyuser.hopshub.groups</name>
           +  <value>*</value>
           +</property>
           +
           +<property>
           +  <name>hadoop.http.staticuser.user</name>
           +  <value>hdfs</value>
           +</property>
           +-->
           +
           +</configuration>
           +
           - change mode from '' to '0755'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/etc/hadoop/hdfs-site.xml] action create_if_missing
           - create new file /srv/hadoop-2.4.0/etc/hadoop/hdfs-site.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/hdfs-site.xml from none to cf182f
           --- /srv/hadoop-2.4.0/etc/hadoop/hdfs-site.xml	2016-08-26 14:16:43.701893808 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-hdfs-site.xml20160826-1220-1m8fq4j	2016-08-26 14:16:43.701893808 +0000
           @@ -1 +1,47 @@
           +<?xml version="1.0"?>
           +<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
           +
           +<configuration>
           +
           +<property>
           +  <name>dfs.replication</name>
           +  <value>3</value>
           +  <description>Default block replication.
           +  The actual number of replications can be specified when the file is created.
           +  The default is used if replication is not specified in create time.
           +  </description>
           +</property>
           +
           +<property>
           +  <name>dfs.client.max.retires.on.failure</name>
           +  <value>1</value>
           +</property>
           +
           +<property>
           +  <name>dfs.client.refresh.namenode.list</name>
           +  <value>60000</value>
           +</property>
           +
           +<property>
           +  <name>dfs.namenode.name.dir</name>
           +  <value>file:/var/data/hadoop/hdfs/nn</value>
           +</property>
           +
           +<property>
           +  <name>dfs.datanode.data.dir</name>
           +  <value>file:/var/data/hadoop/hdfs/dn</value>
           +</property>
           +
           +
           +<property>
           +  <name>dfs.client.block.write.locateFollowingBlock.retries</name>
           +  <value>10</value>
           +</property>
           +
           +<property>
           +  <name>dfs.webhdfs.enabled</name>
           +  <value>true</value>
           +</property>
           +
           +</configuration>
           - change mode from '' to '0755'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/etc/hadoop/hadoop-env.sh] action create
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/hadoop-env.sh from c2941e to 6b9a8d
           --- /srv/hadoop-2.4.0/etc/hadoop/hadoop-env.sh	2014-05-24 22:01:34.000000000 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-hadoop-env.sh20160826-1220-tssrq2	2016-08-26 14:16:43.709889808 +0000
           @@ -24,6 +24,10 @@
            # remote nodes.
            
            # The java implementation to use.
           +if [ -z "$JAVA_HOME" ] ; then
           +  JAVA_HOME=/usr/lib/jvm/java-8-oracle-amd64
           +fi
           +
            export JAVA_HOME=${JAVA_HOME}
            
            # The jsvc implementation to use. Jsvc is required to run secure datanodes.
           @@ -33,7 +37,7 @@
            
            # Extra Java CLASSPATH elements.  Automatically insert capacity-scheduler.
            for f in $HADOOP_HOME/contrib/capacity-scheduler/*.jar; do
           -  if [ "$HADOOP_CLASSPATH" ]; then
           +  if [ "$HADOOP_CLASSPATH" ] ; then
         export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$f
       else
         export HADOOP_CLASSPATH=$f
           @@ -41,11 +45,11 @@
            done
            
            # The maximum amount of heap to use, in MB. Default is 1000.
           -#export HADOOP_HEAPSIZE=
           +export HADOOP_HEAPSIZE=500
            #export HADOOP_NAMENODE_INIT_HEAPSIZE=""
            
            # Extra Java runtime options.  Empty by default.
           -export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
           +export HADOOP_OPTS="-XX:MaxDirectMemorySize=100m $HADOOP_OPTS -Djava.net.preferIPv4Stack=true "
            
            # Command specific options appended to HADOOP_OPTS when specified
            export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
           @@ -53,11 +57,8 @@
            
            export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
            
           -export HADOOP_NFS3_OPTS="$HADOOP_NFS3_OPTS"
           -export HADOOP_PORTMAP_OPTS="-Xmx512m $HADOOP_PORTMAP_OPTS"
           -
            # The following applies to multiple commands (fs, dfs, fsck, distcp etc)
           -export HADOOP_CLIENT_OPTS="-Xmx512m $HADOOP_CLIENT_OPTS"
           +# export HADOOP_CLIENT_OPTS="-Xmx512m $HADOOP_CLIENT_OPTS"
            #HADOOP_JAVA_PLATFORM_OPTS="-XX:-UsePerfData $HADOOP_JAVA_PLATFORM_OPTS"
            
            # On secure datanodes, user to run the datanode as after dropping privileges
           @@ -78,4 +79,6 @@
            
            # A string representing this instance of hadoop. $USER by default.
            export HADOOP_IDENT_STRING=$USER
           +
           +export HADOOP_ROOT_LOGGER=WARN,RFA
           - change mode from '0644' to '0755'
         * template[/srv/hadoop-2.4.0/etc/hadoop/jmxremote.password] action create
           - create new file /srv/hadoop-2.4.0/etc/hadoop/jmxremote.password
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/jmxremote.password from none to 31d0ab
           --- /srv/hadoop-2.4.0/etc/hadoop/jmxremote.password	2016-08-26 14:16:43.725881808 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-jmxremote.password20160826-1220-go9rlf	2016-08-26 14:16:43.725881808 +0000
           @@ -1 +1,2 @@
           +monitorRole hadoop
           - change mode from '' to '0600'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/etc/hadoop/yarn-jmxremote.password] action create
           - create new file /srv/hadoop-2.4.0/etc/hadoop/yarn-jmxremote.password
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/yarn-jmxremote.password from none to 31d0ab
           --- /srv/hadoop-2.4.0/etc/hadoop/yarn-jmxremote.password	2016-08-26 14:16:43.729879808 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-yarn-jmxremote.password20160826-1220-10jimhu	2016-08-26 14:16:43.729879808 +0000
           @@ -1 +1,2 @@
           +monitorRole hadoop
           - change mode from '' to '0600'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/kill-process.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/kill-process.sh
           - update content in file /srv/hadoop-2.4.0/sbin/kill-process.sh from none to c47987
           --- /srv/hadoop-2.4.0/sbin/kill-process.sh	2016-08-26 14:16:43.737875809 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-kill-process.sh20160826-1220-1ym1lvc	2016-08-26 14:16:43.737875809 +0000
           @@ -1 +1,65 @@
           +#!/bin/bash
           +
           +if [ $# -ne 4 ] ; then
           +    echo "Incorrect args. Usage: kill-process service user command_name pid_dir"
           +    exit 1
           +fi
           +
           +SERVICE=$1
           +USER_NAME=$2
           +COMMAND=$3
           +PID_DIR=$4
           +res=1
           +
           +NOT_FOUND=99
           +
           +function kill_named {
           +    PID=`ps aux | grep -i $COMMAND | grep $SERVICE | awk '{print $2}'`
           +    if [ "$PID" != "" ] ; then
           +	kill -9 $PID > /dev/null 2>&1
           +        res=$?
           +    else
           +	res=$NOT_FOUND
           +    fi
           +    return $res
           +}
           +
           +echo "Stopping the $COMMAND"
           +PID_FILE=$PID_DIR/$SERVICE-$USER_NAME-$COMMAND.pid
           +
           +res=1
           +if [ -f $PID_FILE ] ; then
           + PID=`cat $PID_FILE`
           + kill $PID > /dev/null 2>&1
           + res=$?
           +fi
           +
           +if [ $res -ne 0 ] ; then
           +    kill_named
           +else
           +    wait_pid_removed=2
           +    timeout=0
           +    while [ $timeout -lt $wait_pid_removed ] ; do
           +	sleep 1
           +	kill -0 $PID > /dev/null 2>&1 
           +        if [ $? -ne 0 ] ; then 
           +          break
           +        fi
           +	echo -n "."
           +	timeout=`expr $timeout + 1`
           +    done
           +    echo ""
           +
           +    if [ $timeout -eq $wait_pid_removed ] ; then
           +	kill_named
           +    fi
           +fi
           +
           +if [ $res -eq 0 ] ; then
           + echo "Killed $SERVICE/$COMMAND"
           +elif [ $res -eq $NOT_FOUND ] ; then
           +    echo "Could not find $SERVICE/$COMMAND to kill"
           +fi
           +
           +exit $res
           - change mode from '' to '0754'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/set-env.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/set-env.sh
           - update content in file /srv/hadoop-2.4.0/sbin/set-env.sh from none to bff816
           --- /srv/hadoop-2.4.0/sbin/set-env.sh	2016-08-26 14:16:43.753867809 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-set-env.sh20160826-1220-1noxnl	2016-08-26 14:16:43.753867809 +0000
           @@ -1 +1,35 @@
           +#!/bin/bash
           +
           +export JAVA_HOME=/usr/lib/jvm/java-8-oracle-amd64
           +export HADOOP_DEV_HOME=/srv/hadoop
           +export HADOOP_MASTER=$HADOOP_DEV_HOME
           +export HADOOP_COMMON_HOME=$HADOOP_DEV_HOME	
           +export HADOOP_HDFS_HOME=$HADOOP_DEV_HOME			
           +export HADOOP_CONF_DIR=$HADOOP_DEV_HOME/etc/hadoop
           +export HADOOP_HOME=$HADOOP_DEV_HOME			
           +export HADOOP_PID_DIR=$HADOOP_DEV_HOME/logs
           +export HADOOP_LOG_DIR=$HADOOP_DEV_HOME/logs
           +
           +export HADOOP_YARN_HOME=$HADOOP_HOME
           +export YARN_HOME=$HADOOP_HOME
           +export YARN_PID_DIR=$HADOOP_DEV_HOME/logs
           +export YARN_CONF_DIR=$HADOOP_CONF_DIR
           +
           +export HADOOP_CLASSPATH=:.:$HADOOP_HOME/share/hadoop/yarn/test/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/test/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/tools/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/mapreduce/*
           +export CLASSPATH=$HADOOP_CLASSPATH
           +
           +export HADOOP_MAPRED_HOME=$HADOOP_HOME
           +# Extra Java runtime options. Empty by default.
           +# $HADOOP_OPTS gets overwritten in /etc/hadoop/hadoop-env.sh, so make changes in HADOOP_NAMENODE_OPTS, HADOOP_DATANODE_OPTS
           +
           +# Command specific options appended to HADOOP_OPTS when specified
           +export HADOOP_NAMENODE_OPTS='-Dcom.sun.management.jmxremote  -Dcom.sun.management.jmxremote.port=8077 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file='$HADOOP_CONF_DIR'/jmxremote.password'
           +export HADOOP_DATANODE_OPTS='-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8078 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file='$HADOOP_CONF_DIR'/jmxremote.password'
           +
           +export YARN_OPTS='-Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file='$HADOOP_CONF_DIR'/yarn-jmxremote.password'
           +# Command specific options appended to HADOOP_OPTS when specified
           +export YARN_RESOURCEMANAGER_OPTS='-Dcom.sun.management.jmxremote  -Dcom.sun.management.jmxremote.port=8082 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file='$HADOOP_CONF_DIR'/yarn-jmxremote.password'
           +export YARN_NODEMANAGER_OPTS='-Dcom.sun.management.jmxremote  -Dcom.sun.management.jmxremote.port=8083 -Dcom.sun.management.jmxremote.authenticate=true -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.password.file='$HADOOP_CONF_DIR'/yarn-jmxremote.password'
           +
           +export cygwin=false
           - change mode from '' to '0774'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * apache_hadoop_user_envs[hdfs] action update (up to date)
         * bash[update_env_variables_for_user] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1mptfcu"
         * apache_hadoop_user_envs[yarn] action update (up to date)
         * bash[update_env_variables_for_user] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-11jhvu6"
         * apache_hadoop_user_envs[mapred] action update (up to date)
         * bash[update_env_variables_for_user] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1h1vdwf"
         * directory[/conf] action create
           - create new directory /conf
           - change mode from '' to '0755'
           - change owner from '' to 'root'
           - change group from '' to 'hadoop'
         * directory[/srv/hadoop-2.4.0/journal] action create
           - create new directory /srv/hadoop-2.4.0/journal
           - change mode from '' to '0755'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/conf/container-executor.cfg] action create
           - create new file /conf/container-executor.cfg
           - update content in file /conf/container-executor.cfg from none to 3fef51
           --- /conf/container-executor.cfg	2016-08-26 14:16:44.193647821 +0000
           +++ /conf/.chef-container-executor.cfg20160826-1220-q2n3rl	2016-08-26 14:16:44.193647821 +0000
           @@ -1 +1,3 @@
           +yarn.nodemanager.linux-container-executor.group=
           +min.user.id=1000
           - change mode from '' to '0755'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * file[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] action delete (up to date)
         * template[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] action create_if_missing
           - create new file /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml from none to 4da7cd
           --- /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml	2016-08-26 14:16:44.205641821 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-yarn-site.xml20160826-1220-1b84j7q	2016-08-26 14:16:44.205641821 +0000
           @@ -1 +1,227 @@
           +<?xml version="1.0"?>
           +<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
           +<configuration>
           +  <property>
           +    <name>yarn.resourcemanager.resource-tracker.address</name>
           +    <value>10.0.2.15:8031</value>
           +    <description>host is the hostname of the resource manager and port is the port on which the NodeManagers contact the Resource Manager.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.address</name>
           +    <value>10.0.2.15:8030</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.address</name>
           +    <value>10.0.2.15:8032</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.admin.address</name>
           +    <value>10.0.2.15:8033</value>
           +  </property>
           +  <property>
           +    <name>yarn.web-proxy.address</name>
           +    <value>10.0.2.15:20888</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.webapp.address</name>
           +    <value>0.0.0.0:8088</value>
           +    <description>The http address of the RM web application.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.delete.debug-delay-sec</name>
           +    <value>0</value>
           +  </property>
           +  <property>
           +    <description>NM Webapp address.</description>
           +    <name>yarn.nodemanager.webapp.address</name>
           +    <value>10.0.2.15:8042</value>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.address</name>
           +    <value>10.0.2.15:9000</value>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.localizer.address</name>
           +    <value>10.0.2.15:9001</value>
           +  </property>
           +  <property>
           +    <name>yarn.application.classpath</name>
           +    <value>/srv/hadoop-2.4.0, 
           +                                                  /srv/hadoop-2.4.0/lib/*, 
           +                                                  /srv/hadoop-2.4.0/etc/hadoop/,  
           +                                                  /srv/hadoop-2.4.0/share/hadoop/common/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/common/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/hdfs/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/hdfs/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/yarn/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/yarn/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/tools/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/mapreduce/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/mapreduce/lib/*</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.class</name>
           +    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler</value>
           +    <description>In case you do not want to use the default scheduler</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.container-executor.class</name>
           +    <value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value>
           +    <description>LinuxContainerExecutor uses CGroups, DefaultContainerExecutor uses Unix processes.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.group</name>
           +    <value>hadoop</value>
           +  </property>
           +<property>
           +  <name>yarn.nodemanager.container-executor.resources-handler.class</name>
           +  <value>org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler</value>
           +</property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name>
           +    <value>/yarn</value>
           +    <description>LinuxContainerExecutor CGroups hierarchy.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.mount-path</name>
           +    <value>/cgroup</value>
           +    <description>LinuxContainerExecutor CGroups mount-path.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.mount</name>
           +    <value>true</value>
           +    <description>Whether the LCE should attempt to mount cgroups if not found. Only used when the LCE resources handler is set to the CgroupsLCEResourcesHandler.</description>
           +  </property>
           +<property>
           +  <name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
           +  <value>100</value>
           +</property>
           +<property>
           +  <name>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</name>
           +  <value>false</value>
           +</property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.client.thread-count</name>
           +    <value>50</value>
           +    <description>Number of ResourceManager threads for decoding and handling client RPCs for apps.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.resource-tracker.client.thread-count</name>
           +    <value>50</value>
           +    <description>Number of ResourceTracker threads for decoding and handling client RPCs for NodeManager heartbeats.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.admin.client.thread-count</name>
           +    <value>1</value>
           +    <description>Number of ResourceManager threads for decoding and handling client RPCs for Admin operations.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.container-manager.thread-count</name>
           +    <value>20</value>
           +    <description>Number of threads for starting/stopping containers</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.local-dirs</name>
           +    <value>/srv/hadoop-2.4.0/tmp/nm-local-dir</value>
           +    <description>the local directories used by the nodemanager to store its localized files</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.log-dirs</name>
           +    <value></value>
           +    <description>the local directories used by the nodemanager to store its localized logs</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.remote-app-log-dir</name>
           +    <value>/user/yarn/logs</value>
           +    <description>the directory where the logs are aggregated</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.aux-services</name>
           +    <value>mapreduce_shuffle</value>
           +    <description>shuffle service that needs to be set for Map Reduce to run</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
           +    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
           +    <description>The exact name of the class for shuffle service</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.vmem-pmem-ratio</name>
           +    <value>4.1</value>
           +    <description>The virtual memory (physical + paged memory) upper limit for each Map and Reduce task is determined by the virtual memory ratio each YARN Container is allowed.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.vmem-check-enabled</name>
           +    <value>false</value>
           +    <description></description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.pmem-check-enabled</name>
           +    <value>true</value>
           +    <description></description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.resource.memory-mb</name>
           +    <value>3717</value>
           +    <description>the amount of memory on the NodeManager in MB</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.minimum-allocation-mb</name>
           +    <value>128</value>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.maximum-allocation-mb</name>
           +    <value>3717</value>
           +    <description>The maximum allocation for every container request at the RM, in MBs. Memory requests higher than this won't take effect, and will get capped to this value.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.resource.cpu-vcores</name>
           +    <value>4</value>
           +    <description>Number of CPU cores that can be allocated for containers.</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.minimum-allocation-vcores</name>
           +    <value>1</value>
           +    <description>The minimum allocation for every container request at the RM, in terms of virtual CPU cores. Requests lower than this won't take effect, and the specified value will get allocated the minimum.</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.maximum-allocation-vcores</name>
           +    <value>4</value>
           +    <description>The maximum allocation for every container request at the RM, in terms of virtual CPU cores. Requests higher than this won't take effect, and will get capped to this value.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.log.retain-seconds</name>
           +    <value>86400</value>
           +    <description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.am.max-retries</name>
           +    <value>2</value>
           +    <description>Number of times to try to restart the ApplicationMaster by the ResourceManager if its NodeManager fails.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation-enable</name>
           +    <value>true</value>
           +    <description>Enable Default aggregatioin of log files HDFS, deleting them from the NodeManager.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation.retain-seconds</name>
           +    <value>86400</value>
           +    <description>Default time (in seconds) to retain log files in HDFS. Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation.retain-check-interval-seconds</name>
           +    <value>100</value>
           +    <description>Default time (in seconds) between checks for retained log files in HDFS. Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.heartbeat.interval-ms</name>
           +    <value>1000</value>
           +    <description>Time in ms between heartbeats sent from the NodeManager to the ResourceManager.</description>
           +  </property>
           +
           +</configuration>
           - change mode from '' to '0666'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * file[/srv/hadoop-2.4.0/etc/hadoop/mapred-site.xml] action delete (up to date)
         * template[/srv/hadoop-2.4.0/etc/hadoop/mapred-site.xml] action create
           - create new file /srv/hadoop-2.4.0/etc/hadoop/mapred-site.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/mapred-site.xml from none to bd41a2
           --- /srv/hadoop-2.4.0/etc/hadoop/mapred-site.xml	2016-08-26 14:16:44.237625823 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-mapred-site.xml20160826-1220-1xhi0es	2016-08-26 14:16:44.237625823 +0000
           @@ -1 +1,102 @@
           +<?xml version="1.0"?>
           +<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
           +<!--
           +  Licensed under the Apache License, Version 2.0 (the "License");
           +  you may not use this file except in compliance with the License.
           +  You may obtain a copy of the License at
           +
           +    http://www.apache.org/licenses/LICENSE-2.0
           +
           +  Unless required by applicable law or agreed to in writing, software
           +  distributed under the License is distributed on an "AS IS" BASIS,
           +  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
           +  See the License for the specific language governing permissions and
           +  limitations under the License. See accompanying LICENSE file.
           +-->
           +
           +<!-- Put site-specific property overrides in this file. -->
           +
           +<!-- 
           +http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html#Installation
           +-->
           +
           +<configuration>
           +
           +  <property>
           +     <name>mapreduce.framework.name</name>
           +     <value>yarn</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.map.java.opts</name>
           +     <value>-Xmx512M</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.map.memory.mb</name>
           +     <value>512</value>
           +  </property>
           +  <property>
           +     <name>mapreduce.reduce.memory.mb</name>
           +     <value>512</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.job.user.classpath.first</name>
           +     <value>true</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.reduce.java.opts</name>
           +     <value>-Xmx256M</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.task.io.sort.mb</name>
           +     <value>128</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.task.io.sort.factor</name>
           +     <value>100</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.reduce.shuffle.parallelcopies</name>
           +     <value>50</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.cluster.tmp.dir</name>
           +     <value></value>
           +  </property>
           +
           +
           +  <property>
           +     <name>mapreduce.jobhistory.address</name>
           +     <value>10.0.2.15:10020</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.jobhistory.webapp.address</name>
           +     <value>10.0.2.15:19888</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.jobhistory.intermediate-done-dir</name>
           +     <value>/mr-history/done_intermediate</value>
           +  </property>
           +
           +  <property>
           +     <name>mapreduce.jobhistory.done-dir</name>
           +     <value>/mr-history/done</value>
           +  </property>
           +
           +
           +  <property>
           +     <name>yarn.app.mapreduce.am.staging-dir</name>
           +     <value>/mapreduce/mapred/staging</value>
           +  </property>
           +
           +</configuration>
           - change mode from '' to '0666'
           - change owner from '' to 'mapred'
           - change group from '' to 'hadoop'
         * file[/srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml] action delete
           - delete file /srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml
         * template[/srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml] action create
           - create new file /srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml from none to 151d18
           --- /srv/hadoop-2.4.0/etc/hadoop/capacity-scheduler.xml	2016-08-26 14:16:44.257615822 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-capacity-scheduler.xml20160826-1220-r4fnp1	2016-08-26 14:16:44.257615822 +0000
           @@ -1 +1,113 @@
           +<!--
           +  Licensed under the Apache License, Version 2.0 (the "License");
           +  you may not use this file except in compliance with the License.
           +  You may obtain a copy of the License at
           +
           +    http://www.apache.org/licenses/LICENSE-2.0
           +
           +  Unless required by applicable law or agreed to in writing, software
           +  distributed under the License is distributed on an "AS IS" BASIS,
           +  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
           +  See the License for the specific language governing permissions and
           +  limitations under the License. See accompanying LICENSE file.
           +-->
           +<configuration>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.maximum-applications</name>
           +    <value>10000</value>
           +    <description>
           +      Maximum number of applications that can be pending and running.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
           +    <value>20</value>
           +    <description>
           +      Maximum percent of resources in the cluster which can be used to run 
           +      application masters i.e. controls number of concurrent running
           +      applications.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.resource-calculator</name>
           +    <value>org.apache.hadoop.yarn.util.resource.DominantResourceCalculator</value>
           +    <description>
           +      The ResourceCalculator implementation to be used to compare 
           +      Resources in the scheduler.
           +      The default i.e. DefaultResourceCalculator only uses Memory while
           +      DominantResourceCalculator uses dominant-resource to compare 
           +      multi-dimensional resources such as Memory, CPU etc.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.queues</name>
           +    <value>default</value>
           +    <description>
           +      The queues at the this level (root is the root queue).
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.capacity</name>
           +    <value>100</value>
           +    <description>Default queue target capacity.</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
           +    <value>1</value>
           +    <description>
           +      Default queue user limit a percentage from 0.0 to 1.0.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
           +    <value>100</value>
           +    <description>
           +      The maximum capacity of the default queue. 
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.state</name>
           +    <value>RUNNING</value>
           +    <description>
           +      The state of the default queue. State can be one of RUNNING or STOPPED.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
           +    <value>*</value>
           +    <description>
           +      The ACL of who can submit jobs to the default queue.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
           +    <value>*</value>
           +    <description>
           +      The ACL of who can administer jobs on the default queue.
           +    </description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.scheduler.capacity.node-locality-delay</name>
           +    <value>-1</value>
           +    <description>
           +      Number of missed scheduling opportunities after which the CapacityScheduler 
           +      attempts to schedule rack-local containers. 
           +      Typically this should be set to number of racks in the cluster, this 
           +      feature is disabled by default, set to -1.
           +    </description>
           +  </property>
           +
           +</configuration>
           +
           - change mode from '' to '0666'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
       Recipe: apache_hadoop::install
         * bash[update_permissions_etc_dir] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-13wpbva"
         * directory[/srv/hadoop-2.4.0/journal] action create
           - change mode from '0755' to '0775'
       Recipe: apache_hadoop::nn
         * template[/srv/hadoop-2.4.0/sbin/format-nn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/format-nn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/format-nn.sh from none to 6b445b
           --- /srv/hadoop-2.4.0/sbin/format-nn.sh	2016-08-26 14:16:44.313587824 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-format-nn.sh20160826-1220-1dd8ioc	2016-08-26 14:16:44.313587824 +0000
           @@ -1 +1,36 @@
           +#!/bin/bash
           +
           +# set -e
           +
           +command=namenode
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +rootDir=/srv/hadoop
           +
           +HDFS=$rootDir/bin/hdfs
           +log=$rootDir/logs/hadoop-hdfs-$command.log
           +
           +echo "Stopping namenode if running ..."
           +$rootDir/sbin/stop-nn.sh
           +# -force ensures command doesn't user to confirm for re-formatting.
           +echo "$HDFS $command -format -force -nonInteractive > $log"
           +
           +# -force causes us to fail
           +#$HDFS $command -format -force -nonInteractive > "$log"
           +$HDFS $command -format -nonInteractive > "$log"
           +res=$?
           +sleep 5
           +cat "$log"
           +#error=`grep -i error $log`
           +#if [ $error != "" ] ; then
           +#  exit 1
           +#fi
           +exit $res
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/start-nn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/start-nn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/start-nn.sh from none to b7b92c
           --- /srv/hadoop-2.4.0/sbin/start-nn.sh	2016-08-26 14:16:44.325581824 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-start-nn.sh20160826-1220-s1lf0o	2016-08-26 14:16:44.325581824 +0000
           @@ -1 +1,25 @@
           +#!/bin/bash
           +
           +command=namenode
           +h=`hostname`
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +log=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command-$h.log
           +
           +"$bin"/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start $command
           +sleep 2; head "$log"
           +
           +PID_FILE=$HADOOP_PID_DIR/hadoop-hdfs-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           +
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/stop-nn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/stop-nn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/stop-nn.sh from none to f4fa90
           --- /srv/hadoop-2.4.0/sbin/stop-nn.sh	2016-08-26 14:16:44.333577825 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-stop-nn.sh20160826-1220-1jkdsuj	2016-08-26 14:16:44.333577825 +0000
           @@ -1 +1,17 @@
           +#!/bin/bash
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +command=namenode
           +pidDir=$HADOOP_PID_DIR
           +service=hadoop
           +
           +/srv/hadoop/sbin/kill-process.sh $service hdfs $command $pidDir
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/restart-nn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/restart-nn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/restart-nn.sh from none to 658902
           --- /srv/hadoop-2.4.0/sbin/restart-nn.sh	2016-08-26 14:16:44.341573824 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-restart-nn.sh20160826-1220-4u1ezv	2016-08-26 14:16:44.341573824 +0000
           @@ -1 +1,8 @@
           +#!/bin/sh 
           +
           +/srv/hadoop/sbin/stop-nn.sh
           +
           +/srv/hadoop/sbin/start-nn.sh
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/root-start-nn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/root-start-nn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/root-start-nn.sh from none to 55d687
           --- /srv/hadoop-2.4.0/sbin/root-start-nn.sh	2016-08-26 14:16:44.349569825 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-root-start-nn.sh20160826-1220-1fa4oyq	2016-08-26 14:16:44.349569825 +0000
           @@ -1 +1,21 @@
           +#!/bin/bash
           +
           +command=namenode
           +
           +EXEC_WITH_USER="su hdfs -l -c"
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +log=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command-default-ubuntu-1404.log
           +
           +$EXEC_WITH_USER "cd ${bin}/.] ; . ${bin}/../libexec/hadoop-config.sh ; . ${bin}/set-env.sh ; ${bin}/hadoop-daemon.sh --config \$HADOOP_CONF_DIR --script hdfs start $command"
           +sleep 2; head "$log"
           +
           +PID_FILE=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           +
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/hdfs.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/hdfs.sh
           - update content in file /srv/hadoop-2.4.0/sbin/hdfs.sh from none to f4c5bf
           --- /srv/hadoop-2.4.0/sbin/hdfs.sh	2016-08-26 14:16:44.357565826 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-hdfs.sh20160826-1220-1wa0lnd	2016-08-26 14:16:44.357565826 +0000
           @@ -1 +1,15 @@
           +#!/bin/bash
           +
           +command=hdfs
           +
           +# for some reason, .bash_profile isn't sourced with
           +# the -l argument. Source it explicitly.
           +sudo -u hdfs bash -l <<EOF
           +source /home/hdfs/.bash_profile
           +/srv/hadoop/bin/$command $@
           +EOF
           +
           +exit $?
           +
           +
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/yarn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/yarn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/yarn.sh from none to 259f6a
           --- /srv/hadoop-2.4.0/sbin/yarn.sh	2016-08-26 14:16:44.365561825 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-yarn.sh20160826-1220-1w7seyr	2016-08-26 14:16:44.365561825 +0000
           @@ -1 +1,10 @@
           +#!/bin/bash
           +
           +command=yarn
           +
           +sudo -u hdfs bash -l <<EOF
           +/srv/hadoop/bin/$command $@
           +EOF
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/hadoop.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/hadoop.sh
           - update content in file /srv/hadoop-2.4.0/sbin/hadoop.sh from none to dd2cac
           --- /srv/hadoop-2.4.0/sbin/hadoop.sh	2016-08-26 14:16:44.377555826 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-hadoop.sh20160826-1220-3se3ds	2016-08-26 14:16:44.373557825 +0000
           @@ -1 +1,11 @@
           +#!/bin/bash
           +
           +EXEC_WITH_USER="su hdfs -c"
           +
           +$EXEC_WITH_USER "/srv/hadoop/bin/hadoop $@"
           +
           +
           +exit $?
           +
           +
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * apache_hadoop_start[format-nn] action format_nn (up to date)
         * bash[format-nn] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-xeat27"
         * service[namenode] action nothing (skipped due to action :nothing)
         * template[/etc/init.d/namenode] action create
           - create new file /etc/init.d/namenode
           - update content in file /etc/init.d/namenode from none to c536e9
           --- /etc/init.d/namenode	2016-08-26 14:16:51.881802023 +0000
           +++ /etc/init.d/.chef-namenode20160826-1220-1ocx1v6	2016-08-26 14:16:51.881802023 +0000
           @@ -1 +1,92 @@
           +#!/bin/sh
           +#
           +# Startup script for namenode
           +#
           +### BEGIN INIT INFO
           +# Provides:                     namenode-*
           +# Required-Start:               $all
           +# Required-Stop:                $all
           +# Default-Start:                2 3 4 5
           +# Default-Stop:                 0 1 6
           +# Short-Description:            start and stop namenode-*
           +# Description:                  Start/Stop/Restart Namenode
           +### END INIT INFO
           +
           +# Variables
           +
           +START_PROG="/srv/hadoop/sbin/start-nn.sh"  
           +STOP_PROG="/srv/hadoop/sbin/stop-nn.sh"  
           +
           +EXEC_WITH_USER="su hdfs -c"
           +
           +start() {
           +  ulimit -n 65000 2>&1 > /dev/null
           +  $EXEC_WITH_USER "$START_PROG"
           +  return $?
           +}
           +
           +stop() {
           +  "$STOP_PROG"
           +  return $?
           +}
           +
           +status() {
           +  PID_FILE=/srv/hadoop-2.4.0/logs/hadoop-hdfs-namenode.pid
           +  res=1
           +  if [ -f $PID_FILE ] ; then
           +     PID=`cat $PID_FILE`
           +     kill -0 $PID
           +     res=$?
           +  fi
           +  if [ $res -eq 0 ] ; then
           +   echo "namenode($PID) is running"
           +  else
           +   echo "namenode is not running"
           +  fi
           +  return $res
           +}
           +
           +
           +restart() {
           +  status
           +  if [ $? -eq 0 ] ; then
           +    stop
           +    sleep 3
           +  fi
           +  start
           +  return $?
           +}
           +
           +
           +
           +# user-supplied parameter to stop/start/restart process.
           +case "$1" in
           +  start)
           +    start
           +    ;;
           +  stop)
           +    stop
           +    ;;
           +  restart)
           +    restart
           +    ;;
           +  reload)
           +    restart
           +    ;;
           +  status)
           +    status
           +    ;;
           +  -h|--help)
           +    echo ""
           +    echo "usage: <prog> start|stop|restart|status"
           +    echo ""
           +    exit 0
           +    ;;
           +  *)
           +    echo $"Usage: <prog> {start|stop|restart|status}"
           +    exit 1
           +  esac
           +
           +
           +exit $?
           - change mode from '' to '0754'
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * service[namenode] action restart
           - restart service service[namenode]
         * apache_hadoop_hdfs_directory[/tmp] action create_as_superuser (up to date)
         * bash[mk-dir-/tmp] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1ij1w0f"
         * apache_hadoop_hdfs_directory[/user] action create_as_superuser (up to date)
         * bash[mk-dir-/user] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-m3v7wq"
         * apache_hadoop_hdfs_directory[/user/hdfs] action create_as_superuser (up to date)
         * bash[mk-dir-/user/hdfs] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-9p6z8p"
       Recipe: apache_hadoop::dn
         * template[/srv/hadoop-2.4.0/sbin/start-dn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/start-dn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/start-dn.sh from none to 4773b4
           --- /srv/hadoop-2.4.0/sbin/start-dn.sh	2016-08-26 14:17:40.281591303 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-start-dn.sh20160826-1220-w89i6k	2016-08-26 14:17:40.281591303 +0000
           @@ -1 +1,22 @@
           +#!/bin/bash
           +
           +command=datanode
           +h=`hostname`
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +log=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command-$h.log
           +
           +"$bin"/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start $command
           +sleep 2; head "$log"
           +
           +PID_FILE=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/stop-dn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/stop-dn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/stop-dn.sh from none to c0c47c
           --- /srv/hadoop-2.4.0/sbin/stop-dn.sh	2016-08-26 14:17:40.289587303 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-stop-dn.sh20160826-1220-vj4kuy	2016-08-26 14:17:40.289587303 +0000
           @@ -1 +1,17 @@
           +#!/bin/bash
           +
           +command=datanode
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +pidDir=$HADOOP_PID_DIR
           +service=hadoop
           +
           +/srv/hadoop/sbin/kill-process.sh $service hdfs $command $pidDir
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/restart-dn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/restart-dn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/restart-dn.sh from none to caa274
           --- /srv/hadoop-2.4.0/sbin/restart-dn.sh	2016-08-26 14:17:40.297583304 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-restart-dn.sh20160826-1220-el7mqw	2016-08-26 14:17:40.297583304 +0000
           @@ -1 +1,8 @@
           +#!/bin/sh 
           +
           +/srv/hadoop/sbin/stop-dn.sh
           +
           +/srv/hadoop/sbin/start-dn.sh
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/root-start-dn.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/root-start-dn.sh
           - update content in file /srv/hadoop-2.4.0/sbin/root-start-dn.sh from none to bcf79c
           --- /srv/hadoop-2.4.0/sbin/root-start-dn.sh	2016-08-26 14:17:40.301581303 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-root-start-dn.sh20160826-1220-1ato6pr	2016-08-26 14:17:40.301581303 +0000
           @@ -1 +1,20 @@
           +#!/bin/bash
           +
           +command=datanode
           +
           +EXEC_WITH_USER="su hdfs -l -c"
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +log=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command-default-ubuntu-1404.log
           +
           +$EXEC_WITH_USER "cd ${bin}/.] ; . ${bin}/../libexec/hadoop-config.sh ; . ${bin}/set-env.sh ; ${bin}/hadoop-daemon.sh --config \$HADOOP_CONF_DIR --script hdfs start $command"
           +sleep 2; head "$log"
           +
           +PID_FILE=/srv/hadoop-2.4.0/logs/hadoop-hdfs-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'hdfs'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/hdfs.sh] action create (up to date)
         * template[/srv/hadoop-2.4.0/sbin/yarn.sh] action create (up to date)
         * template[/srv/hadoop-2.4.0/sbin/hadoop.sh] action create (up to date)
         * service[datanode] action nothing (skipped due to action :nothing)
         * template[/etc/init.d/datanode] action create
           - create new file /etc/init.d/datanode
           - update content in file /etc/init.d/datanode from none to 559beb
           --- /etc/init.d/datanode	2016-08-26 14:17:40.333565304 +0000
           +++ /etc/init.d/.chef-datanode20160826-1220-1294q9q	2016-08-26 14:17:40.333565304 +0000
           @@ -1 +1,91 @@
           +#!/bin/sh
           +#
           +# Startup script for namenode
           +#
           +### BEGIN INIT INFO
           +# Provides:                     datanode-*
           +# Required-Start:                 
           +# Should-Start:                 
           +# Required-Stop:                  
           +# Default-Start:                2 3 4 5
           +# Default-Stop:                 0 1 6
           +# Short-Description:            start and stop datanode-*
           +# Description:                  Start/Stop/Restart datanode
           +### END INIT INFO
           +
           +# Variables
           +
           +START_PROG="/srv/hadoop/sbin/start-dn.sh"  
           +STOP_PROG="/srv/hadoop/sbin/stop-dn.sh"  
           +
           +EXEC_WITH_USER="su hdfs -c"
           +
           +start() {
           +  ulimit -n 65000 2>&1 > /dev/null
           +  $EXEC_WITH_USER "$START_PROG"
           +  return $?
           +}
           +
           +stop() {
           +  "$STOP_PROG"
           +  return $?
           +}
           +
           +status() {
           +  PID_FILE=/srv/hadoop-2.4.0/logs/hadoop-hdfs-datanode.pid
           +  res=1
           +  if [ -f $PID_FILE ] ; then
           +     PID=`cat $PID_FILE`
           +     kill -0 $PID
           +     res=$?
           +  fi
           +  if [ $res -eq 0 ] ; then
           +   echo "datanode($PID) is running"
           +  else
           +   echo "datanode is not running"
           +  fi
           +  return $res
           +}
           +
           +restart() {
           +  status
           +  if [ $? -eq 0 ] ; then
           +    stop
           +    sleep 3
           +  fi
           +  start
           +  return $?
           +}
           +
           +
           +# user-supplied parameter to stop/start/restart process.
           +case "$1" in
           +  start)
           +    start
           +    ;;
           +  stop)
           +    stop
           +    ;;
           +  restart)
           +    restart
           +    ;;
           +  reload)
           +    restart
           +    ;;
           +  status)
           +    status
           +    ;;
           +  -h|--help)
           +    echo ""
           +    echo "usage: <prog> start|stop|restart|status"
           +    echo ""
           +    exit 0
           +    ;;
           +  *)
           +    echo $"Usage: <prog> {start|stop|restart|status}"
           +    exit 1
           +  esac
           +
           +
           +exit $?
           - change mode from '' to '0754'
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * service[datanode] action restart
           - restart service service[datanode]
         * kagent_config[datanode] action add
         
       Recipe: apache_hadoop::rm
         * file[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] action delete
           - delete file /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml
         * template[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] action create_if_missing
           - create new file /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml
           - update content in file /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml from none to 4da7cd
           --- /srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml	2016-08-26 14:17:46.538461468 +0000
           +++ /srv/hadoop-2.4.0/etc/hadoop/.chef-yarn-site.xml20160826-1220-gi8qhd	2016-08-26 14:17:46.538461468 +0000
           @@ -1 +1,227 @@
           +<?xml version="1.0"?>
           +<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
           +<configuration>
           +  <property>
           +    <name>yarn.resourcemanager.resource-tracker.address</name>
           +    <value>10.0.2.15:8031</value>
           +    <description>host is the hostname of the resource manager and port is the port on which the NodeManagers contact the Resource Manager.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.address</name>
           +    <value>10.0.2.15:8030</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.address</name>
           +    <value>10.0.2.15:8032</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.admin.address</name>
           +    <value>10.0.2.15:8033</value>
           +  </property>
           +  <property>
           +    <name>yarn.web-proxy.address</name>
           +    <value>10.0.2.15:20888</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.webapp.address</name>
           +    <value>0.0.0.0:8088</value>
           +    <description>The http address of the RM web application.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.delete.debug-delay-sec</name>
           +    <value>0</value>
           +  </property>
           +  <property>
           +    <description>NM Webapp address.</description>
           +    <name>yarn.nodemanager.webapp.address</name>
           +    <value>10.0.2.15:8042</value>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.address</name>
           +    <value>10.0.2.15:9000</value>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.localizer.address</name>
           +    <value>10.0.2.15:9001</value>
           +  </property>
           +  <property>
           +    <name>yarn.application.classpath</name>
           +    <value>/srv/hadoop-2.4.0, 
           +                                                  /srv/hadoop-2.4.0/lib/*, 
           +                                                  /srv/hadoop-2.4.0/etc/hadoop/,  
           +                                                  /srv/hadoop-2.4.0/share/hadoop/common/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/common/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/hdfs/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/hdfs/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/yarn/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/yarn/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/tools/lib/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/mapreduce/*, 
           +                                                  /srv/hadoop-2.4.0/share/hadoop/mapreduce/lib/*</value>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.class</name>
           +    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler</value>
           +    <description>In case you do not want to use the default scheduler</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.container-executor.class</name>
           +    <value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value>
           +    <description>LinuxContainerExecutor uses CGroups, DefaultContainerExecutor uses Unix processes.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.group</name>
           +    <value>hadoop</value>
           +  </property>
           +<property>
           +  <name>yarn.nodemanager.container-executor.resources-handler.class</name>
           +  <value>org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler</value>
           +</property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</name>
           +    <value>/yarn</value>
           +    <description>LinuxContainerExecutor CGroups hierarchy.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.mount-path</name>
           +    <value>/cgroup</value>
           +    <description>LinuxContainerExecutor CGroups mount-path.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.linux-container-executor.cgroups.mount</name>
           +    <value>true</value>
           +    <description>Whether the LCE should attempt to mount cgroups if not found. Only used when the LCE resources handler is set to the CgroupsLCEResourcesHandler.</description>
           +  </property>
           +<property>
           +  <name>yarn.nodemanager.resource.percentage-physical-cpu-limit</name>
           +  <value>100</value>
           +</property>
           +<property>
           +  <name>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</name>
           +  <value>false</value>
           +</property>
           +  <property>
           +    <name>yarn.resourcemanager.scheduler.client.thread-count</name>
           +    <value>50</value>
           +    <description>Number of ResourceManager threads for decoding and handling client RPCs for apps.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.resource-tracker.client.thread-count</name>
           +    <value>50</value>
           +    <description>Number of ResourceTracker threads for decoding and handling client RPCs for NodeManager heartbeats.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.admin.client.thread-count</name>
           +    <value>1</value>
           +    <description>Number of ResourceManager threads for decoding and handling client RPCs for Admin operations.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.container-manager.thread-count</name>
           +    <value>20</value>
           +    <description>Number of threads for starting/stopping containers</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.local-dirs</name>
           +    <value>/srv/hadoop-2.4.0/tmp/nm-local-dir</value>
           +    <description>the local directories used by the nodemanager to store its localized files</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.log-dirs</name>
           +    <value></value>
           +    <description>the local directories used by the nodemanager to store its localized logs</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.remote-app-log-dir</name>
           +    <value>/user/yarn/logs</value>
           +    <description>the directory where the logs are aggregated</description>
           +  </property>
           +
           +  <property>
           +    <name>yarn.nodemanager.aux-services</name>
           +    <value>mapreduce_shuffle</value>
           +    <description>shuffle service that needs to be set for Map Reduce to run</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
           +    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
           +    <description>The exact name of the class for shuffle service</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.vmem-pmem-ratio</name>
           +    <value>4.1</value>
           +    <description>The virtual memory (physical + paged memory) upper limit for each Map and Reduce task is determined by the virtual memory ratio each YARN Container is allowed.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.vmem-check-enabled</name>
           +    <value>false</value>
           +    <description></description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.pmem-check-enabled</name>
           +    <value>true</value>
           +    <description></description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.resource.memory-mb</name>
           +    <value>3717</value>
           +    <description>the amount of memory on the NodeManager in MB</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.minimum-allocation-mb</name>
           +    <value>128</value>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.maximum-allocation-mb</name>
           +    <value>3717</value>
           +    <description>The maximum allocation for every container request at the RM, in MBs. Memory requests higher than this won't take effect, and will get capped to this value.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.resource.cpu-vcores</name>
           +    <value>4</value>
           +    <description>Number of CPU cores that can be allocated for containers.</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.minimum-allocation-vcores</name>
           +    <value>1</value>
           +    <description>The minimum allocation for every container request at the RM, in terms of virtual CPU cores. Requests lower than this won't take effect, and the specified value will get allocated the minimum.</description>
           +  </property>
           +  <property>
           +    <name>yarn.scheduler.maximum-allocation-vcores</name>
           +    <value>4</value>
           +    <description>The maximum allocation for every container request at the RM, in terms of virtual CPU cores. Requests higher than this won't take effect, and will get capped to this value.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.log.retain-seconds</name>
           +    <value>86400</value>
           +    <description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.resourcemanager.am.max-retries</name>
           +    <value>2</value>
           +    <description>Number of times to try to restart the ApplicationMaster by the ResourceManager if its NodeManager fails.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation-enable</name>
           +    <value>true</value>
           +    <description>Enable Default aggregatioin of log files HDFS, deleting them from the NodeManager.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation.retain-seconds</name>
           +    <value>86400</value>
           +    <description>Default time (in seconds) to retain log files in HDFS. Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.log-aggregation.retain-check-interval-seconds</name>
           +    <value>100</value>
           +    <description>Default time (in seconds) between checks for retained log files in HDFS. Only applicable if log-aggregation is disabled.</description>
           +  </property>
           +  <property>
           +    <name>yarn.nodemanager.heartbeat.interval-ms</name>
           +    <value>1000</value>
           +    <description>Time in ms between heartbeats sent from the NodeManager to the ResourceManager.</description>
           +  </property>
           +
           +</configuration>
           - change mode from '' to '0666'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/start-rm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/start-rm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/start-rm.sh from none to eddc5c
           --- /srv/hadoop-2.4.0/sbin/start-rm.sh	2016-08-26 14:17:46.566447469 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-start-rm.sh20160826-1220-1y6xovx	2016-08-26 14:17:46.566447469 +0000
           @@ -1 +1,25 @@
           +#!/bin/bash
           +
           +command=resourcemanager
           +h=`hostname`
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +log=/srv/hadoop-2.4.0/logs/yarn-yarn-$command-$h.log
           +
           +"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start $command
           +sleep 2; head "$log"
           +
           +#PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-$command.pid
           +PID_FILE=$YARN_PID_DIR/yarn-yarn-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/stop-rm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/stop-rm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/stop-rm.sh from none to 81e45b
           --- /srv/hadoop-2.4.0/sbin/stop-rm.sh	2016-08-26 14:17:46.578441469 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-stop-rm.sh20160826-1220-1a4lqxr	2016-08-26 14:17:46.578441469 +0000
           @@ -1 +1,17 @@
           +#!/bin/bash
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +command=resourcemanager
           +#pidDir=/srv/hadoop-2.4.0/logs
           +pidDir=$YARN_PID_DIR
           +service=yarn
           +
           +/srv/hadoop/sbin/kill-process.sh $service yarn $command $pidDir
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/restart-rm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/restart-rm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/restart-rm.sh from none to d9f456
           --- /srv/hadoop-2.4.0/sbin/restart-rm.sh	2016-08-26 14:17:46.586437470 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-restart-rm.sh20160826-1220-1rzyko1	2016-08-26 14:17:46.586437470 +0000
           @@ -1 +1,8 @@
           +#!/bin/sh 
           +
           +/srv/hadoop/sbin/stop-rm.sh
           +
           +/srv/hadoop/sbin/start-rm.sh
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/root-start-rm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/root-start-rm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/root-start-rm.sh from none to 26b2fd
           --- /srv/hadoop-2.4.0/sbin/root-start-rm.sh	2016-08-26 14:17:46.594433471 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-root-start-rm.sh20160826-1220-1tvhnte	2016-08-26 14:17:46.594433471 +0000
           @@ -1 +1,22 @@
           +#!/bin/bash
           +
           +command=resourcemanager
           +EXEC_WITH_USER="su yarn -l -c"
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +log=/srv/hadoop-2.4.0/logs/yarn-yarn-$command-default-ubuntu-1404.log
           +
           +$EXEC_WITH_USER "cd ${bin}/.] ; . ${bin}/../libexec/hadoop-config.sh ; . ${bin}/set-env.sh ; ${bin}/yarn-daemon.sh --config \$YARN_CONF_DIR  start $command"
           +sleep 2; head "$log"
           +
           +PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           +
           +
           +
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/yarn.sh] action create
           - change owner from 'hdfs' to 'yarn'
         * service[resourcemanager] action nothing (skipped due to action :nothing)
         * template[/etc/init.d/resourcemanager] action create
           - create new file /etc/init.d/resourcemanager
           - update content in file /etc/init.d/resourcemanager from none to 75262d
           --- /etc/init.d/resourcemanager	2016-08-26 14:17:46.610425470 +0000
           +++ /etc/init.d/.chef-resourcemanager20160826-1220-1wkhzax	2016-08-26 14:17:46.610425470 +0000
           @@ -1 +1,88 @@
           +#!/bin/sh
           +#
           +# Startup script for resource-manager
           +#
           +### BEGIN INIT INFO
           +# Provides:                     resource-manager-*
           +# Required-Start:                 
           +# Should-Start:                 
           +# Required-Stop:                  
           +# Default-Start:                2 3 4 5
           +# Default-Stop:                 0 1 6
           +# Short-Description:            start and stop resource-manager-*
           +# Description:                  Start/Stop/Restart Resource-Manager
           +### END INIT INFO
           +
           +# Variables
           +
           +START_PROG="/srv/hadoop/sbin/start-rm.sh"  
           +STOP_PROG="/srv/hadoop/sbin/stop-rm.sh"  
           +
           +EXEC_WITH_USER="su yarn -c"
           +
           +start() {
           +  ulimit -n 65000 2>&1 > /dev/null
           +  $EXEC_WITH_USER "$START_PROG"
           +  return $?
           +}
           +
           +stop() {
           +  "$STOP_PROG"
           +  return $?
           +}
           +
           +status() {
           +  PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-resourcemanager.pid
           +  res=1
           +  if [ -f $PID_FILE ] ; then
           +     PID=`cat $PID_FILE`
           +     kill -0 $PID
           +     res=$?
           +  fi
           +  if [ $res -eq 0 ] ; then
           +   echo "resourcemanager($PID) is running"
           +  else
           +   echo "resourcemanager is not running"
           +  fi
           +  return $res
           +}
           +
           +restart() {
           +  status
           +  if [ $? -eq 0 ] ; then
           +    stop
           +    sleep 3
           +  fi
           +  start
           +  return $?
           +}
           +
           +
           +# user-supplied parameter to stop/start/restart process.
           +case "$1" in
           +  start)
           +    start
           +    ;;
           +  stop)
           +    stop
           +    ;;
           +  restart)
           +    restart
           +    ;;
           +  status)
           +    status
           +    ;;
           +  -h|--help)
           +    echo ""
           +    echo "usage: <prog> start|stop|restart|status"
           +    echo ""
           +    exit 0
           +    ;;
           +  *)
           +    echo $"Usage: <prog> {start|stop|restart|status}"
           +    exit 1
           +  esac
           +
           +
           +exit $?
           - change mode from '' to '0754'
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * kagent_config[resourcemanager] action add
         
         * apache_hadoop_hdfs_directory[/user/yarn] action create_as_superuser (up to date)
         * bash[mk-dir-/user/yarn] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1sugdjs"
         * apache_hadoop_hdfs_directory[/user/yarn/logs] action create_as_superuser (up to date)
         * bash[mk-dir-/user/yarn/logs] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-33z4k5"
       Recipe: apache_hadoop::nm
         * template[/srv/hadoop-2.4.0/sbin/start-nm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/start-nm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/start-nm.sh from none to 4d322a
           --- /srv/hadoop-2.4.0/sbin/start-nm.sh	2016-08-26 14:18:13.409020180 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-start-nm.sh20160826-1220-18jg22v	2016-08-26 14:18:13.409020180 +0000
           @@ -1 +1,26 @@
           +#!/bin/bash
           +
           +command=nodemanager
           +h=`hostname`
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +
           +log=/srv/hadoop-2.4.0/logs/yarn-yarn-$command-$h.log
           +
           +"$bin"/yarn-daemon.sh --config $YARN_CONF_DIR  start $command
           +sleep 2; head "$log"
           +
           +#PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-$command.pid
           +PID_FILE=$YARN_PID_DIR/yarn-yarn-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/stop-nm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/stop-nm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/stop-nm.sh from none to 0d6761
           --- /srv/hadoop-2.4.0/sbin/stop-nm.sh	2016-08-26 14:18:13.421014178 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-stop-nm.sh20160826-1220-6z2kig	2016-08-26 14:18:13.421014178 +0000
           @@ -1 +1,16 @@
           +#!/bin/bash
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +command=nodemanager
           +pidDir=$YARN_PID_DIR
           +service=yarn
           +
           +/srv/hadoop/sbin/kill-process.sh $service yarn $command $pidDir
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/restart-nm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/restart-nm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/restart-nm.sh from none to 649e34
           --- /srv/hadoop-2.4.0/sbin/restart-nm.sh	2016-08-26 14:18:13.429010180 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-restart-nm.sh20160826-1220-1cluvnu	2016-08-26 14:18:13.429010180 +0000
           @@ -1 +1,8 @@
           +#!/bin/sh 
           +
           +/srv/hadoop/sbin/stop-nm.sh
           +
           +/srv/hadoop/sbin/start-nm.sh
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/root-start-nm.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/root-start-nm.sh
           - update content in file /srv/hadoop-2.4.0/sbin/root-start-nm.sh from none to 87c9f9
           --- /srv/hadoop-2.4.0/sbin/root-start-nm.sh	2016-08-26 14:18:13.437006178 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-root-start-nm.sh20160826-1220-1debujh	2016-08-26 14:18:13.437006178 +0000
           @@ -1 +1,19 @@
           +#!/bin/bash
           +
           +command=nodemanager
           +EXEC_WITH_USER="su yarn -l -c"
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +log=/srv/hadoop-2.4.0/logs/yarn-yarn-$command-default-ubuntu-1404.log
           +
           +$EXEC_WITH_USER "cd ${bin}/.] ; . ${bin}/../libexec/hadoop-config.sh ; . ${bin}/set-env.sh ; ${bin}/yarn-daemon.sh --config \$YARN_CONF_DIR  start $command"
           +sleep 2; head "$log"
           +
           +PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * service[nodemanager] action nothing (skipped due to action :nothing)
         * template[/etc/init.d/nodemanager] action create
           - create new file /etc/init.d/nodemanager
           - update content in file /etc/init.d/nodemanager from none to 28f6f8
           --- /etc/init.d/nodemanager	2016-08-26 14:18:13.445002180 +0000
           +++ /etc/init.d/.chef-nodemanager20160826-1220-3ratam	2016-08-26 14:18:13.445002180 +0000
           @@ -1 +1,90 @@
           +#!/bin/sh
           +#
           +# Startup script for nodemanager
           +#
           +### BEGIN INIT INFO
           +# Provides:                     nodemanager-*
           +# Required-Start:                 
           +# Should-Start:                 
           +# Required-Stop:                  
           +# Default-Start:                2 3 4 5
           +# Default-Stop:                 0 1 6
           +# Short-Description:            start and stop nodemanager-*
           +# Description:                  Start/Stop/Restart Nodemanager
           +### END INIT INFO
           +
           +# Variables
           +
           +START_PROG="/srv/hadoop/sbin/start-nm.sh"  
           +STOP_PROG="/srv/hadoop/sbin/stop-nm.sh"  
           +
           +EXEC_WITH_USER="su yarn -c"
           +
           +start() {
           +  $EXEC_WITH_USER "$START_PROG"
           +  return $?
           +}
           +
           +stop() {
           +  "$STOP_PROG"
           +  return $?
           +}
           +
           +status() {
           +  PID_FILE=/srv/hadoop-2.4.0/logs/yarn-yarn-nodemanager.pid
           +  res=1
           +  if [ -f $PID_FILE ] ; then
           +     PID=`cat $PID_FILE`
           +     kill -0 $PID
           +     res=$?
           +  fi
           +  if [ $res -eq 0 ] ; then
           +   echo "nodemanager($PID) is running"
           +  else
           +   echo "nodemanager is not running"
           +  fi
           +  return $res
           +}
           +
           +
           +restart() {
           +  status
           +  if [ $? -eq 0 ] ; then
           +    stop
           +    sleep 3
           +  fi
           +  start
           +  return $?
           +}
           +
           +# user-supplied parameter to stop/start/restart process.
           +case "$1" in
           +  start)
           +    start
           +    ;;
           +  stop)
           +    stop
           +    ;;
           +  restart)
           +    restart
           +    ;;
           +  reload)
           +    restart
           +    ;;
           +  status)
           +    status
           +    ;;
           +  -h|--help)
           +    echo ""
           +    echo "usage: <prog> start|stop|restart|status"
           +    echo ""
           +    exit 0
           +    ;;
           +  *)
           +    echo $"Usage: <prog> {start|stop|restart|status}"
           +    exit 1
           +  esac
           +
           +
           +exit $?
           - change mode from '' to '0754'
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * kagent_config[nodemanager] action add
         
       Recipe: apache_hadoop::jhs
         * template[/srv/hadoop-2.4.0/sbin/start-jhs.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/start-jhs.sh
           - update content in file /srv/hadoop-2.4.0/sbin/start-jhs.sh from none to dc85ae
           --- /srv/hadoop-2.4.0/sbin/start-jhs.sh	2016-08-26 14:18:13.464992181 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-start-jhs.sh20160826-1220-15kcinl	2016-08-26 14:18:13.464992181 +0000
           @@ -1 +1,25 @@
           +#!/bin/bash
           +
           +command=historyserver
           +h=`hostname`
           +rootDir=/srv/hadoop
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +MRJH=$rootDir/sbin/mr-jobhistory-daemon.sh
           +
           +echo "Starting $command on ..."
           +$MRJH --config $HADOOP_CONF_DIR start $command 
           +
           +sleep 2; head /srv/hadoop-2.4.0/logs/mapred-mapred-$command-$h.log
           +
           +PID_FILE=/tmp/mapred-mapred-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/stop-jhs.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/stop-jhs.sh
           - update content in file /srv/hadoop-2.4.0/sbin/stop-jhs.sh from none to e7b5bf
           --- /srv/hadoop-2.4.0/sbin/stop-jhs.sh	2016-08-26 14:18:13.472988181 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-stop-jhs.sh20160826-1220-5qvce0	2016-08-26 14:18:13.472988181 +0000
           @@ -1 +1,16 @@
           +#!/bin/bash
           +
           +command=historyserver
           +pidDir=/tmp
           +service=mapred
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +DEFAULT_LIBEXEC_DIR="$bin"/../libexec
           +HADOOP_LIBEXEC_DIR=${HADOOP_LIBEXEC_DIR:-$DEFAULT_LIBEXEC_DIR}
           +. $HADOOP_LIBEXEC_DIR/hadoop-config.sh
           +. ${bin}/set-env.sh
           +
           +/srv/hadoop/sbin/kill-process.sh $service yarn $command $pidDir
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/restart-jhs.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/restart-jhs.sh
           - update content in file /srv/hadoop-2.4.0/sbin/restart-jhs.sh from none to 32b3df
           --- /srv/hadoop-2.4.0/sbin/restart-jhs.sh	2016-08-26 14:18:13.476986180 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-restart-jhs.sh20160826-1220-18xm0pz	2016-08-26 14:18:13.476986180 +0000
           @@ -1 +1,8 @@
           +#!/bin/sh 
           +
           +/srv/hadoop/sbin/stop-mrjh.sh
           +
           +/srv/hadoop/sbin/start-mrjh.sh
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * template[/srv/hadoop-2.4.0/sbin/root-start-jhs.sh] action create
           - create new file /srv/hadoop-2.4.0/sbin/root-start-jhs.sh
           - update content in file /srv/hadoop-2.4.0/sbin/root-start-jhs.sh from none to 394c49
           --- /srv/hadoop-2.4.0/sbin/root-start-jhs.sh	2016-08-26 14:18:13.488980181 +0000
           +++ /srv/hadoop-2.4.0/sbin/.chef-root-start-jhs.sh20160826-1220-8ksdkn	2016-08-26 14:18:13.488980181 +0000
           @@ -1 +1,24 @@
           +#!/bin/bash
           +
           +command=historyserver
           +EXEC_WITH_USER="su mapred -l -c"
           +
           +bin=`dirname "${BASH_SOURCE-$0}"`
           +bin=`cd "$bin"; pwd`
           +
           +rootDir=/srv/hadoop
           +
           +MRJH=$rootDir/sbin/mr-jobhistory-daemon.sh
           +
           +echo "Starting $command on ..."
           +
           +$EXEC_WITH_USER "cd ${bin}/.] ; . ${bin}/../libexec/hadoop-config.sh ; . ${bin}/set-env.sh ; $MRJH --config \$HADOOP_CONF_DIR start $command"
           +
           +sleep 2
           +head /srv/hadoop-2.4.0/logs/mapred-yarn-historyserver-default-ubuntu-1404.log
           +PID_FILE=/tmp/mapred-yarn-$command.pid
           +PID=`cat $PID_FILE` 
           +kill -0 $PID 
           +
           +exit $?
           - change mode from '' to '0775'
           - change owner from '' to 'yarn'
           - change group from '' to 'hadoop'
         * apache_hadoop_hdfs_directory[/mr-history] action create_as_superuser (up to date)
         * bash[mk-dir-/mr-history] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-182v7p2"
         * apache_hadoop_hdfs_directory[/mr-history/done_intermediate] action create_as_superuser (up to date)
         * bash[mk-dir-/mr-history/done_intermediate] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-160dsi5"
         * apache_hadoop_hdfs_directory[/mr-history/done] action create_as_superuser (up to date)
         * bash[mk-dir-/mr-history/done] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-10rjldf"
         * apache_hadoop_hdfs_directory[/mapreduce/mapred/staging] action create_as_superuser (up to date)
         * bash[mk-dir-/mapreduce/mapred/staging] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1egdfwx"
         * apache_hadoop_hdfs_directory[/mapreduce] action create_as_superuser (skipped due to not_if)
         * apache_hadoop_hdfs_directory[/user/mapred] action create_as_superuser (up to date)
         * bash[mk-dir-/user/mapred] action run
           - execute "bash"  "/tmp/chef-script20160826-1220-1fky4xp"
         * service[historyserver] action nothing (skipped due to action :nothing)
         * template[/etc/init.d/historyserver] action create
           - create new file /etc/init.d/historyserver
           - update content in file /etc/init.d/historyserver from none to 45771c
           --- /etc/init.d/historyserver	2016-08-26 14:19:22.898260015 +0000
           +++ /etc/init.d/.chef-historyserver20160826-1220-zgim9	2016-08-26 14:19:22.898260015 +0000
           @@ -1 +1,90 @@
           +#!/bin/sh
           +#
           +# Startup script for historyserver
           +#
           +### BEGIN INIT INFO
           +# Provides:                     historyserver-*
           +# Required-Start:                 
           +# Should-Start:                 
           +# Required-Stop:                  
           +# Default-Start:                2 3 4 5
           +# Default-Stop:                 0 1 6
           +# Short-Description:            start and stop historyserver-*
           +# Description:                  Start/Stop/Restart Historyserver
           +### END INIT INFO
           +
           +# Variables
           +
           +START_PROG="/srv/hadoop/sbin/start-jhs.sh"  
           +STOP_PROG="/srv/hadoop/sbin/stop-jhs.sh"  
           +
           +EXEC_WITH_USER="su mapred -c"
           +
           +start() {
           +  $EXEC_WITH_USER "$START_PROG"
           +  return $?
           +}
           +
           +stop() {
           +  "$STOP_PROG"
           +  return $?
           +}
           +
           +status() {
           +  PID_FILE=/tmp/mapred-yarn-historyserver.pid
           +  res=1
           +  if [ -f $PID_FILE ] ; then
           +     PID=`cat $PID_FILE`
           +     kill -0 $PID
           +     res=$?
           +  fi
           +  if [ $res -eq 0 ] ; then
           +   echo "jobhistoryserver($PID) is running"
           +  else
           +   echo "jobhistoryserver is not running"
           +  fi
           +  return $res
           +}
           +
           +restart() {
           +  status
           +  if [ $? -eq 0 ] ; then
           +    stop
           +    sleep 3
           +  fi
           +  start
           +  return $?
           +}
           +
           +
           +# user-supplied parameter to stop/start/restart process.
           +case "$1" in
           +  start)
           +    start
           +    ;;
           +  stop)
           +    stop
           +    ;;
           +  restart)
           +    restart
           +    ;;
           +  reload)
           +    restart
           +    ;;
           +  status)
           +    status
           +    ;;
           +  -h|--help)
           +    echo ""
           +    echo "usage: <prog> start|stop|restart|status"
           +    echo ""
           +    exit 0
           +    ;;
           +  *)
           +    echo "Usage: <prog> {start|stop|restart|status}"
           +    exit 1
           +  esac
           +
           +
           +exit $?
           - change mode from '' to '0754'
           - change owner from '' to 'root'
           - change group from '' to 'root'
         * service[historyserver] action restart
           - restart service service[historyserver]
         * kagent_config[historyserver] action add
         
       Recipe: apache_hadoop::nn
         * service[namenode] action enable
           - enable service service[namenode]
       Recipe: apache_hadoop::dn
         * service[datanode] action enable
           - enable service service[datanode]
       Recipe: apache_hadoop::rm
         * service[resourcemanager] action enable
           - enable service service[resourcemanager]
         * service[resourcemanager] action restart
           - restart service service[resourcemanager]
       Recipe: apache_hadoop::nm
         * service[nodemanager] action enable
           - enable service service[nodemanager]
         * service[nodemanager] action restart
           - restart service service[nodemanager]
       Recipe: apache_hadoop::jhs
         * service[historyserver] action enable
           - enable service service[historyserver]
       
       Running handlers:
       Running handlers complete
       
       Deprecated features used!
         method access to node attributes (node.foo.bar) is deprecated and will be removed in Chef 13, please use bracket syntax (node["foo"]["bar"]) at 387 locations:
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:6:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:9:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:10:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:14:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:47:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:55:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/attributes/default.rb:61:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:7:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:8:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:9:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:10:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:11:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:12:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:13:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:15:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:16:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:22:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:23:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:27:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:57:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:72:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:73:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:74:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:75:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:76:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:77:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:78:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:79:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:80:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:81:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:82:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/attributes/default.rb:83:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:3:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:40:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:42:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:45:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:47:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:50:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:51:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:53:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:57:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:60:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:62:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:66:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:68:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:76:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:77:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:85:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:86:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:94:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:95:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:103:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:104:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:111:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:112:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:136:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:137:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:145:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:146:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:154:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:155:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:211:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:212:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:213:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:219:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:220:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:221:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:228:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:230:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:233:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:234:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:235:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:236:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:241:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:242:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:243:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:250:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:251:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:252:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:259:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:260:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:266:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/libraries/default.rb:21:in `my_private_ip'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:268:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:271:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:276:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:290:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:296:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:298:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:299:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:304:in `from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:306:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:307:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:314:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:316:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:317:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:324:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:326:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:327:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:333:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:336:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:348:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:349:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:350:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:351:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:352:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:353:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:354:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:355:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:2:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:4:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:10:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:23:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:51:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:53:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:56:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:59:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:62:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:65:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:67:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:71:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:74:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:76:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:80:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:83:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:85:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:89:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:104:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:198:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:199:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:200:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:207:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:208:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:209:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:216:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:217:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:218:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:224:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:225:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:226:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:232:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:233:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:242:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:243:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:256:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:257:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:264:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:270:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:271:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:273:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:274:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:276:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:277:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:278:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:279:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:281:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:287:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:321:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:322:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:323:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:328:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:329:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:330:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:335:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:336:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/libraries/default.rb:11:in `my_public_ip'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:9:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:19:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:24:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:26:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:27:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:46:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:50:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:57:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:58:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:74:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:76:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:77:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:82:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:84:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:85:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:89:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:91:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:92:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:97:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:99:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:100:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:104:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:106:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:107:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:112:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:113:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:114:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:116:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:147:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:148:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:152:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:156:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:163:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:170:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:171:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:172:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:180:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:181:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:187:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:192:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:193:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:194:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:195:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:204:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:205:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:209:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:211:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:212:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:217:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:226:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:227:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:231:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:233:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:234:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:242:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:243:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:247:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:249:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:250:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:346:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:350:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:379:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:380:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:381:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:2:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:4:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:12:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:13:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:15:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:16:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:23:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:32:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:82:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:147:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:156:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:161:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:162:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:164:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:2:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:4:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:9:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:10:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:12:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:13:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:14:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:21:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:86:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:87:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:88:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/yarn.rb:7:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/yarn.rb:9:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:8:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:13:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:14:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:18:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:20:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:21:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:26:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:35:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:36:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:38:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:39:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:44:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:46:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:47:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:52:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:121:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:122:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:123:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:130:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:134:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:135:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:137:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:7:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:8:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:10:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:11:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:17:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:83:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nm.rb:84:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:7:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:8:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:10:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:11:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:17:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:23:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:24:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:26:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:30:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:31:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:35:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:36:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:38:in `block (2 levels) in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:42:in `from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:109:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:110:in `block in from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/jhs.rb:111:in `block in from_file'
           - (erubis):61:in `block in evaluate'
           - (erubis):62:in `block in evaluate'
           - (erubis):63:in `block in evaluate'
           - (erubis):164:in `block in evaluate'
           - (erubis):165:in `block in evaluate'
           - (erubis):166:in `block in evaluate'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:204:in `block (2 levels) in from_file'
           - (erubis):11:in `block in evaluate'
           - (erubis):17:in `block in evaluate'
           - (erubis):23:in `block in evaluate'
           - (erubis):8:in `block in evaluate'
           - (erubis):27:in `block in evaluate'
           - (erubis):32:in `block in evaluate'
           - (erubis):28:in `block in evaluate'
           - (erubis):48:in `block in evaluate'
           - (erubis):52:in `block in evaluate'
           - (erubis):83:in `block in evaluate'
           - (erubis):1:in `block in evaluate'
           - (erubis):3:in `block in evaluate'
           - (erubis):4:in `block in evaluate'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:17:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:18:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:20:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:22:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:23:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:24:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:25:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:26:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:27:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:29:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:30:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:32:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:33:in `block (2 levels) in class_from_file'
           - (erubis):49:in `block in evaluate'
           - (erubis):53:in `block in evaluate'
           - (erubis):64:in `block in evaluate'
           - (erubis):115:in `block in evaluate'
           - (erubis):126:in `block in evaluate'
           - (erubis):132:in `block in evaluate'
           - (erubis):137:in `block in evaluate'
           - (erubis):142:in `block in evaluate'
           - (erubis):147:in `block in evaluate'
           - (erubis):152:in `block in evaluate'
           - (erubis):171:in `block in evaluate'
           - (erubis):176:in `block in evaluate'
           - (erubis):181:in `block in evaluate'
           - (erubis):186:in `block in evaluate'
           - (erubis):191:in `block in evaluate'
           - (erubis):196:in `block in evaluate'
           - (erubis):201:in `block in evaluate'
           - (erubis):206:in `block in evaluate'
           - (erubis):211:in `block in evaluate'
           - (erubis):87:in `block in evaluate'
           - (erubis):92:in `block in evaluate'
           - (erubis):98:in `block in evaluate'
           - (erubis):36:in `block in evaluate'
           - (erubis):15:in `block in evaluate'
           - (erubis):18:in `block in evaluate'
           - (erubis):14:in `block in evaluate'
           - (erubis):19:in `block in evaluate'
           - (erubis):5:in `block in evaluate'
           - (erubis):10:in `block in evaluate'
           - (erubis):7:in `block in evaluate'
           - (erubis):6:in `block in evaluate'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/start.rb:39:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/start.rb:42:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/start.rb:43:in `block (2 levels) in class_from_file'
           - (erubis):20:in `block in evaluate'
           - (erubis):34:in `block in evaluate'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:77:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:78:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:80:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:81:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:82:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:83:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:85:in `block (2 levels) in class_from_file'
           - /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/hdfs_directory.rb:88:in `block (2 levels) in class_from_file'
           - (erubis):12:in `block in evaluate'
           - (erubis):21:in `block in evaluate'
           - (erubis):35:in `block in evaluate'
           - /tmp/kitchen/cache/cookbooks/kagent/providers/config.rb:2:in `block in class_from_file'
           - /tmp/kitchen/cache/cookbooks/kagent/providers/config.rb:3:in `block in class_from_file'
           - (erubis):9:in `block in evaluate'
           - (erubis):13:in `block in evaluate'
         Cloning resource attributes for group[kagent] from prior resource (CHEF-3694)
       Previous group[kagent]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:40:in `from_file'
       Current  group[kagent]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:60:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for group[certs] from prior resource (CHEF-3694)
       Previous group[certs]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:45:in `from_file'
       Current  group[certs]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:66:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for link[/var/lib/kagent] from prior resource (CHEF-3694)
       Previous link[/var/lib/kagent]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:228:in `from_file'
       Current  link[/var/lib/kagent]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:233:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for hostsfile_entry[10.0.2.15] from prior resource (CHEF-3694)
       Previous hostsfile_entry[10.0.2.15]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:270:in `from_file'
       Current  hostsfile_entry[10.0.2.15]: /tmp/kitchen/cache/cookbooks/kagent/recipes/install.rb:275:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for group[hadoop] from prior resource (CHEF-3694)
       Previous group[hadoop]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:51:in `from_file'
       Current  group[hadoop]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:83:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for remote_file[/tmp/hadoop-2.4.0.tar.gz] from prior resource (CHEF-3694)
       Previous remote_file[/tmp/hadoop-2.4.0.tar.gz]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:239:in `from_file'
       Current  remote_file[/tmp/hadoop-2.4.0.tar.gz]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:253:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for directory[/srv/hadoop-2.4.0/journal] from prior resource (CHEF-3694)
       Previous directory[/srv/hadoop-2.4.0/journal]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:170:in `from_file'
       Current  directory[/srv/hadoop-2.4.0/journal]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/install.rb:379:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for template[/srv/hadoop-2.4.0/sbin/hdfs.sh] from prior resource (CHEF-3694)
       Previous template[/srv/hadoop-2.4.0/sbin/hdfs.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:13:in `block in from_file'
       Current  template[/srv/hadoop-2.4.0/sbin/hdfs.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:10:in `block in from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for template[/srv/hadoop-2.4.0/sbin/yarn.sh] from prior resource (CHEF-3694)
       Previous template[/srv/hadoop-2.4.0/sbin/yarn.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:13:in `block in from_file'
       Current  template[/srv/hadoop-2.4.0/sbin/yarn.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:10:in `block in from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for template[/srv/hadoop-2.4.0/sbin/hadoop.sh] from prior resource (CHEF-3694)
       Previous template[/srv/hadoop-2.4.0/sbin/hadoop.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/nn.rb:13:in `block in from_file'
       Current  template[/srv/hadoop-2.4.0/sbin/hadoop.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:10:in `block in from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for file[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] from prior resource (CHEF-3694)
       Previous file[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:204:in `from_file'
       Current  file[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:13:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for template[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml] from prior resource (CHEF-3694)
       Previous template[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/default.rb:209:in `from_file'
       Current  template[/srv/hadoop-2.4.0/etc/hadoop/yarn-site.xml]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:18:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for template[/srv/hadoop-2.4.0/sbin/yarn.sh] from prior resource (CHEF-3694)
       Previous template[/srv/hadoop-2.4.0/sbin/yarn.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/dn.rb:10:in `block in from_file'
       Current  template[/srv/hadoop-2.4.0/sbin/yarn.sh]: /tmp/kitchen/cache/cookbooks/apache_hadoop/recipes/rm.rb:44:in `from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
         Cloning resource attributes for bash[update_env_variables_for_user] from prior resource (CHEF-3694)
       Previous bash[update_env_variables_for_user]: /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:6:in `block in class_from_file'
       Current  bash[update_env_variables_for_user]: /tmp/kitchen/cache/cookbooks/apache_hadoop/providers/user_envs.rb:6:in `block in class_from_file' at 1 location:
           - /tmp/kitchen/cache/cookbooks/poise/files/halite_gem/poise/helpers/resource_cloning.rb:58:in `emit_cloned_resource_warning'
       
       Chef Client finished, 148/189 resources updated in 05 minutes 04 seconds
       Finished converging <default-ubuntu-1404> (5m56.53s).
-----> Kitchen is finished. (6m53.60s)
