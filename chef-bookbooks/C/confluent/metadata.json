{"name":"confluent","version":"1.3.0","description":"Installs/Configures confluent","long_description":"Confluent Cookbook\n==================\n\n[![Cookbook Version](https://img.shields.io/cookbook/v/confluent.svg)](https://community.opscode.com/cookbooks/confluent)\n[![Build Status](https://travis-ci.org/bbaugher/confluent.svg?branch=master)](https://travis-ci.org/bbaugher/confluent)\n\nInstalls the [Confluent](http://confluent.io/) package and can run its services,\n\n * Kafka\n * Kafka REST\n * Schema Registry\n * Kafka Connect\n\nView the [Change Log](CHANGELOG.md) to see what has changed.\n\nGetting Started\n---------------\n\n### Install Confluent Package\n\nIf you include the `recipe[confluent]` this will install the Confluent package and nothing else.\n\nYou can find the package installed under `/opt/confluent` (by default) with the name `confluent-VERSION`.\n\nYou can also find the configuration under,\n\n * /etc/kafka\n * /etc/kafka-rest\n * /etc/schema-registry\n * /etc/kafka-connect\n\n### Kafka Service\n\nIf you include the `recipe[confluent::kafka]` this will install the Confluent package, configure and start the Kafka service.\n\nYou can configure the service using the attribtues `node[\"confluent\"][\"kafka\"][\"server.properties\"][...] = ...`.\nUse Confluent's [Kafka doc](http://docs.confluent.io/current/kafka/deployment.html#important-configuration-options)\nto figure out the appropriate configuration for yourself.\n\nYou can find the SysV script at `/etc/init.d/kafka-rest` or `service kafka-rest [start|stop|restart|status]`.\n\nYou can find the logs at `/var/log/confluent/kafka.log`.\n\n### Kafka REST Service\n\nIf you include the `recipe[confluent::kafka-rest]` this will install the Confluent package, configure and start the\nKafka REST service.\n\nYou can configure the service using the attribtues `node[\"confluent\"][\"kafka-rest\"][\"kafka-rest.properties\"][...] = ...`.\nUse Confluent's [Kafka REST doc](http://docs.confluent.io/current/kafka-rest/docs/config.html) to figure out the\nappropriate configuration for yourself.\n\nYou can find the SysV script at `/etc/init.d/kafka-rest` or `service kafka-rest [start|stop|restart|status]`.\n\nYou can find the logs at `/var/log/confluent/kafka-rest.log`.\n\n### Schema Registry Service\n\nIf you include the `recipe[confluent::schema-registry]` this will install the Confluent package, configure and start the\nSchema Registry service.\n\nYou can configure the service using the attribtues `node[\"confluent\"][\"schema-registry\"][\"schema-registry.properties\"][...] = ...`.\nUse Confluent's [Schema Registry doc](http://docs.confluent.io/current/schema-registry/docs/config.html) to figure out the\nappropriate configuration for yourself.\n\nYou can find the SysV script at `/etc/init.d/schema-registry` or `service schema-registry [start|stop|restart|status]`.\n\nYou can find the logs at `/var/log/confluent/schema-registry.log`.\n\n### Kafka Connect\n\nIf you include the `recipe[confluent::kafka-connect]` this will install the Confluent package, configure and start the\nKafka connector. This will listen on port 8083 exposing its rest api to control spinning up new connectors.\n\nYou can configure the service using the attribtues `node[\"confluent\"][\"kafka-connect\"][\"worker.properties\"][...] = ...`.\nUse Confluent's [Kafka Connect doc](http://docs.confluent.io/2.0.0/connect/userguide.html) to figure out the\nappropriate configuration for yourself.\n\nYou can find the SysV script at `/etc/init.d/kafka-connect` or `service kafka-connect [start|stop|restart|status]`.\n\nYou can find the logs at `/var/log/confluent/kafka-connect.log`.\n\n### Zookeeper (For development purposes only)\n\nIf you include the `recipe[confluent::zookeeper]` this will install the Confluent package and start a zookeeper process. It will listen on port 2181. This is a single zookeeper worker and is not recomended for production use. The primary purpose of this recipe is to get everything running inside vagrant as a self contained system without having to run process on the host machine.\n\n### Kerberos\n\nThe cookbook helps to setup the services with kerberos enabled. To do so,\n\n * Set `node[\"confluent\"][\"kerberos\"][\"enable\"]` to `true`\n * Set a value for `node[\"confluent\"][\"kerberos\"][\"keytab\"]`\n * Set a value for `node[\"confluent\"][\"kerberos\"][\"realm\"]` or `node[\"confluent\"][\"kerberos\"][\"principal\"]`\n\nThe cookbook will create a JAAS configuration file to be used for the services and\nautomatically include the `-Djava.security.auth.login.config` java option.\n\nThe cookbook however will not handle creating and kerberos keytab files. That is\noutside the scope of this cookbook.\n\nZooKeeper client authentication can additionally be enabled by setting\n`node[\"kafka\"][\"kerberos\"][\"enable_zk\"]` to `true`.\n\nCustom Krb5LoginModule options can be set using the `node[\"kafka\"][\"kerberos\"][\"krb5_properties\"]`\nattribute hash for Kafka, or `node[\"kafka\"][\"kerberos\"][\"zk_krb5_properties\"]`\nfor ZooKeeper (see attributes file for defaults).\n\nNote that enabling Kerberos does not automatically set any configuration into\nany of the service's property/config files. Those should be evaluated as well.\n\nAttributes\n----------\n\n### Generic\n\n * `node[\"confluent\"][\"version\"]` : The version of the Confluent package to install (default=`2.0.1`)\n * `node[\"confluent\"][\"scala_version\"]` : The scala version of the Confluent package to install (default=`2.11.7`)\n * `node[\"confluent\"][\"artifact_url\"]` : The URL to the Confluent package to install. This is generated using the `version` and `scala_version` attributes. It downloads from `packages.confluent.io`.\n * `node[\"confluent\"][\"install_dir\"]` : The directory to install the Confluent package (default=`/opt/confluent`)\n * `node[\"confluent\"][\"user\"]` : The user that owns the Confluent package files and runs the services (default=`confluent`)\n * `node[\"confluent\"][\"uid\"]` : optional staticly assign a uid for above user (default=`unset` picks form system config)\n * `node[\"confluent\"][\"group\"]` : The group that owns the Confluent package files and runs the services (default=`confluent`)\n * `node[\"confluent\"][\"gid\"]` : optional staticly assign a gid for above group (default=`unset` picks form system config)\n * `node[\"confluent\"][\"backup_templates\"]` : If template backups are desired set this to the number of backups to keep. (default=`false`)\n * `node[\"confluent\"][\"kerberos\"][\"enable\"]` : if kerberos configuration should be applied (default=`false`)\n * `node[\"confluent\"][\"kerberos\"][\"keytab\"]` : the path to the kerberos keytab file (default=`nil`)\n * `node[\"confluent\"][\"kerberos\"][\"realm\"]` : the name of the kerberos realm to use (default=`nil`)\n * `node[\"confluent\"][\"kerberos\"][\"principal\"]` : the kerberos principal to use (default is dynamically generated from other attributes. See attributes file)\n * `node[\"confluent\"][\"kerberos\"][\"enable_zk\"]` : if zookeeper kerberos configuration should be applied (default=`false`)\n * `node[\"confluent\"][\"kerberos\"][\"krb5_properties\"]` : a hash of krb5 key/values used for kerberos kafka server/client configuration (See attributes file for default)\n * `node[\"confluent\"][\"kerberos\"][\"zk_krb5_properties\"]` : a hash of krb5 key/values used for kerberos zookeeper client configuration (See attributes file for default)\n\n### Kafka\n\n * `node[\"confluent\"][\"kafka\"][\"server.properties\"]` : A Hash of properties that configure the Kafka service (default=`{}`)\n * `node[\"confluent\"][\"kafka\"][\"env_vars\"]` : A Hash of environment variables applied when running the service\n * `node[\"confluent\"][\"kafka\"][\"log4j.properties\"]` : A Hash of properties that configure log4j for the Kafka service (see attributes for defaults)\n * `node['confluent']['kafka']['brokers']` : A single broker String or List of brokers by hostname, fqdn, or ipaddress\n * `node['confluent']['kafka']['zookeepers']` : A list of zookeeper hostname:port's to add to kafka config (default=`nil`)\n * `node['confluent']['kafka']['zookeeper_chroot']` : An optional chroot path for zookeeper hostname:port/chroot's to add to kafka config (default=`nil`)\n\n### Kafka REST\n\n * `node[\"confluent\"][\"kafka-rest\"][\"kafka-rest.properties\"]` : A Hash of properties that configure the Kafka REST service (default=`{}`)\n * `node[\"confluent\"][\"kafka-rest\"][\"env_vars\"]` : A Hash of environment variables applied when running the service\n * `node[\"confluent\"][\"kafka-rest\"][\"log4j.properties\"]` : A Hash of properties that configure log4j for the Kafka REST service (see attributes for defaults)\n\n### Schema Registry\n\n * `node[\"confluent\"][\"schema-registry\"][\"schema-registry.properties\"]` : A Hash of properties that configure the Schema Registry service (default=`{}`)\n * `node[\"confluent\"][\"schema-registry\"][\"env_vars\"]` : A Hash of environment variables applied when running the service\n * `node[\"confluent\"][\"schema-registry\"][\"log4j.properties\"]` : A Hash of properties that configure log4j for the Schema Registry service (see attributes for defaults)\n\n### Kafka Connect\n* `node[\"confluent\"][\"kafka-connect\"][\"jar_urls\"]` : an array of urls to remote files to download and install in the directory `share/java/kafka-connect-all` located in the extracted confluent directory which is where connect looks by default.\n* `node[\"confluent\"][\"kafka-connect\"][\"properties_files\"]` : a hash where the key is a property file name, and the value is a hash of keys/values for the property file. This is can be used to drop in connector configuration for standalone mode via chef config as opposed to the rest api.\n* `node[\"confluent\"][\"kafka-connect\"][\"distributed_mode\"]` : Boolean used to decide if it should launch in standalone or distributed mode. Defaults to true\n* `node[\"confluent\"][\"kafka-connect\"][\"worker_properties_file_name\"]` : The name of the properties file to use when starting the connect service.\n* `node[\"confluent\"][\"kafka-connect\"][\"worker.properties\"]` : hash of properties to configure the connect properties with.\n* `node[\"confluent\"][\"kafka-connect\"][\"env_vars\"]` : A Hash of environment variables applied when running the service\n* `node[\"confluent\"][\"kafka-connect\"][\"log4j.properties\"]` : A Hash of properties that configure log4j for the Schema Registry service (see attributes for defaults)\n\n### Zookeeper\n* `node[\"confluent\"][\"zookeeper\"][\"zookeeper.properties\"]` : a hash of properties to configure the zookeeper server with\n\nTesting\n-------\n\n### Style\n* `rake style` : runs foodcritic and rubocop\n  * todo in .rubocop.yml\n* `rake unit` : runs chefspec tests form ./spec\n  * todo from untouched resources\n* `rake kitchen` : runs kitchen tests\n  * problem with gem version conflict in Rakefile.  Run kitchen from command line: `kitchen test`\n","maintainer":"Bryan Baugher","maintainer_email":"Bryan.Baugher@Cerner.com","license":"All rights reserved","platforms":{"ubuntu":">= 0.0.0","centos":">= 0.0.0"},"dependencies":{"java":">= 0.0.0"},"recommendations":{},"suggestions":{},"conflicting":{},"providing":{},"replacing":{},"attributes":{},"groupings":{},"recipes":{}}